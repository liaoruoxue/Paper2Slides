# Paper2Slides ä»£ç åº“å®Œæ•´è¯´æ˜æ–‡æ¡£

## ğŸ“š ç›®å½•
- [ç¬¬ä¸€å±‚ï¼šå¿«é€Ÿå…¥é—¨](#ç¬¬ä¸€å±‚å¿«é€Ÿå…¥é—¨)
- [ç¬¬äºŒå±‚ï¼šæ·±å…¥ç†è§£](#ç¬¬äºŒå±‚æ·±å…¥ç†è§£)
- [ç¬¬ä¸‰å±‚ï¼šé«˜çº§å¼€å‘](#ç¬¬ä¸‰å±‚é«˜çº§å¼€å‘)

---

# ç¬¬ä¸€å±‚ï¼šå¿«é€Ÿå…¥é—¨

## ğŸ¯ é¡¹ç›®ç®€ä»‹

**Paper2Slides** æ˜¯ä¸€ä¸ªå°†å­¦æœ¯è®ºæ–‡è‡ªåŠ¨è½¬æ¢ä¸ºä¸“ä¸šæ¼”ç¤ºå¹»ç¯ç‰‡å’Œæµ·æŠ¥çš„ AI ç³»ç»Ÿã€‚

### æ ¸å¿ƒåŠŸèƒ½
- ğŸ“„ **è¾“å…¥**ï¼šPDF/DOCX/PPTX/MD æ–‡æ¡£
- ğŸ¨ **è¾“å‡º**ï¼šç²¾ç¾çš„å¹»ç¯ç‰‡ï¼ˆPNGåºåˆ— + PDFï¼‰æˆ–æµ·æŠ¥
- ğŸ¤– **æŠ€æœ¯**ï¼šRAG + GPT-4o + Gemini å›¾åƒç”Ÿæˆ

### å¿«é€Ÿä½¿ç”¨

```bash
# 1. å®‰è£…ä¾èµ–
pip install -e .

# 2. é…ç½® API å¯†é’¥
cp paper2slides/.env.example paper2slides/.env
# ç¼–è¾‘ .env å¡«å…¥ API å¯†é’¥ï¼ˆæ”¯æŒ OpenRouter æˆ– Google GenAIï¼‰

# 3. ç”Ÿæˆå¹»ç¯ç‰‡
python -m paper2slides --input paper.pdf --style doraemon --length medium
```

### å›¾åƒç”Ÿæˆæä¾›å•†é…ç½®

ç³»ç»Ÿæ”¯æŒä¸¤ç§å›¾åƒç”Ÿæˆæä¾›å•†ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡åˆ‡æ¢ï¼š

#### OpenRouterï¼ˆé»˜è®¤ï¼‰
```bash
# .env
IMAGE_GEN_PROVIDER="openrouter"
IMAGE_GEN_API_KEY="your-openrouter-api-key"
IMAGE_GEN_MODEL="google/gemini-3-pro-image-preview"
```

#### Google GenAIï¼ˆç›´è¿ï¼‰
```bash
# .env
IMAGE_GEN_PROVIDER="google"
GOOGLE_API_KEY="your-google-api-key"
IMAGE_GEN_MODEL="gemini-3-pro-image-preview"

# éœ€è¦å®‰è£…é¢å¤–ä¾èµ–
pip install google-generativeai
```

### ä¸¤ç§ä½¿ç”¨æ¨¡å¼

#### CLI æ¨¡å¼ï¼ˆå‘½ä»¤è¡Œï¼‰
```bash
python -m paper2slides \
  --input paper.pdf \           # è¾“å…¥æ–‡ä»¶
  --output slides \             # slides æˆ– poster
  --poster-format portrait_a0 \ # æµ·æŠ¥æ ¼å¼ï¼šlandscape (16:9) æˆ– portrait_a0 (A0ç«–å‘)
  --style academic \            # é£æ ¼ï¼šacademic, doraemon, æˆ–è‡ªå®šä¹‰
  --length medium \             # å¹»ç¯ç‰‡é•¿åº¦ï¼šshort, medium, long
  --density medium \            # æµ·æŠ¥å¯†åº¦ï¼šsparse, medium, dense
  --fast \                      # å¿«é€Ÿæ¨¡å¼ï¼ˆè·³è¿‡ RAGï¼‰
  --parallel 2                  # å¹¶è¡Œç”Ÿæˆæ•°é‡
```

#### æµ·æŠ¥æ ¼å¼è¯´æ˜
- `landscape`ï¼š16:9 æ¨ªå‘æµ·æŠ¥ï¼ˆé»˜è®¤ï¼‰
- `portrait_a0`ï¼šA0 ç«–å‘å­¦æœ¯æµ·æŠ¥ï¼ˆ841mm x 1189mmï¼‰

```bash
# ç”Ÿæˆ A0 ç«–å‘å­¦æœ¯æµ·æŠ¥
python -m paper2slides --input paper.pdf --output poster --poster-format portrait_a0 --style academic

# ç”Ÿæˆ A0 ç«–å‘ Doraemon é£æ ¼æµ·æŠ¥
python -m paper2slides --input paper.pdf --output poster --poster-format portrait_a0 --style doraemon --density dense
```

#### Web æ¨¡å¼ï¼ˆå›¾å½¢ç•Œé¢ï¼‰
```bash
# å¯åŠ¨æœåŠ¡
bash scripts/start.sh

# è®¿é—® http://localhost:5173
# æ‹–æ‹½ä¸Šä¼ æ–‡ä»¶ â†’ é€‰æ‹©é…ç½® â†’ ç”Ÿæˆ â†’ é¢„è§ˆä¸‹è½½
```

---

## ğŸ“ é¡¹ç›®ç»“æ„ï¼ˆç®€åŒ–ç‰ˆï¼‰

```
Paper2Slides/
â”œâ”€â”€ paper2slides/          # æ ¸å¿ƒ Python åº“
â”‚   â”œâ”€â”€ main.py           # CLI å…¥å£
â”‚   â”œâ”€â”€ core/             # æµæ°´çº¿ç¼–æ’
â”‚   â”œâ”€â”€ raganything/      # RAG å¼•æ“
â”‚   â”œâ”€â”€ summary/          # å†…å®¹æå–
â”‚   â”œâ”€â”€ generator/        # å›¾åƒç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ config.py     # é…ç½®ç±»ï¼ˆOutputType, PosterFormat, StyleTypeç­‰ï¼‰
â”‚   â”‚   â”œâ”€â”€ providers.py  # å›¾åƒç”Ÿæˆæä¾›å•†ï¼ˆOpenRouter/GoogleGenAIï¼‰
â”‚   â”‚   â”œâ”€â”€ image_generator.py  # å›¾åƒç”Ÿæˆä¸»é€»è¾‘
â”‚   â”‚   â””â”€â”€ content_planner.py  # å†…å®¹è§„åˆ’
â”‚   â””â”€â”€ prompts/          # LLM æç¤ºè¯
â”‚
â”œâ”€â”€ api/                  # Web API (FastAPI)
â”œâ”€â”€ frontend/             # React å‰ç«¯
â”œâ”€â”€ scripts/              # å¯åŠ¨è„šæœ¬
â””â”€â”€ outputs/              # ç”Ÿæˆç»“æœ
```

---

## ğŸ”„ å·¥ä½œæµç¨‹ï¼ˆå››é˜¶æ®µï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è¾“å…¥æ–‡æ¡£   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ1: RAG (æ–‡æ¡£è§£æä¸ç´¢å¼•)     â”‚
â”‚ - Fastæ¨¡å¼: ç›´æ¥ç”¨GPT-4oåˆ†æ    â”‚
â”‚ - Normalæ¨¡å¼: æ„å»ºRAGç´¢å¼•       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ2: Summary (å†…å®¹æå–)       â”‚
â”‚ - æå–è®ºæ–‡å…ƒæ•°æ®                â”‚
â”‚ - æå–å„ç« èŠ‚å†…å®¹                â”‚
â”‚ - æå–è¡¨æ ¼å’Œå›¾ç‰‡                â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ3: Plan (å†…å®¹è§„åˆ’)          â”‚
â”‚ - ç¡®å®šé¡µæ•°å’Œå¸ƒå±€                â”‚
â”‚ - åˆ†é…å†…å®¹åˆ°å„é¡µ                â”‚
â”‚ - åŒ¹é…å›¾è¡¨åˆ°å¯¹åº”é¡µé¢            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ4: Generate (å›¾åƒç”Ÿæˆ)      â”‚
â”‚ - å¹»ç¯ç‰‡ï¼šå‰2é¡µé¡ºåº+åç»­å¹¶è¡Œ    â”‚
â”‚ - æµ·æŠ¥ï¼šå•å¼ ç”Ÿæˆï¼ˆæ”¯æŒæ¨ª/ç«–å‘ï¼‰ â”‚
â”‚ - åˆæˆä¸ºPDF                     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è¾“å‡ºç»“æœ   â”‚ slides.pdf/poster.png + PDF
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ å¯ç”¨é£æ ¼

### å†…ç½®é£æ ¼
1. **academic** - å­¦æœ¯ä¸“ä¸šé£æ ¼ï¼ˆæ·±è“è‰² + ç™½è‰²èƒŒæ™¯ï¼‰
2. **doraemon** - å“†å•¦Aæ¢¦å‹å¥½é£æ ¼ï¼ˆå¤©è“è‰² + å¡é€šå…ƒç´ ï¼‰

### æµ·æŠ¥æ ¼å¼
| æ ¼å¼ | å°ºå¯¸ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| `landscape` | 16:9 æ¨ªå‘ | å¿«é€Ÿæ¦‚è§ˆã€åœ¨çº¿åˆ†äº« |
| `portrait_a0` | 841mm x 1189mm ç«–å‘ | å­¦æœ¯ä¼šè®®ã€æµ·æŠ¥å±•ç¤º |

### è‡ªå®šä¹‰é£æ ¼
```bash
# ç›´æ¥ç”¨è‡ªç„¶è¯­è¨€æè¿°
python -m paper2slides \
  --input paper.pdf \
  --style "èµ›åšæœ‹å…‹ç§‘å¹»é£æ ¼ï¼Œéœ“è™¹è‰²è°ƒï¼Œæ·±è‰²èƒŒæ™¯"
```

---

## ğŸš€ è¾“å‡ºç¤ºä¾‹

### è¾“å‡ºç›®å½•ç»“æ„
```
outputs/
â””â”€â”€ my_paper/                          # é¡¹ç›®å
    â””â”€â”€ paper/                         # å†…å®¹ç±»å‹
        â””â”€â”€ normal/                    # æ¨¡å¼ (fast/normal)
            â”œâ”€â”€ checkpoint_rag.json    # æ–­ç‚¹æ–‡ä»¶ï¼ˆfast æ¨¡å¼æ— ï¼‰
            â”œâ”€â”€ checkpoint_summary.json
            â”‚
            â”œâ”€â”€ slides_doraemon_medium/       # å¹»ç¯ç‰‡é…ç½®
            â”‚   â””â”€â”€ 20231210_143052/          # æ—¶é—´æˆ³
            â”‚       â”œâ”€â”€ slide_01.png
            â”‚       â”œâ”€â”€ slide_02.png
            â”‚       â””â”€â”€ slides.pdf
            â”‚
            â”œâ”€â”€ poster_academic_medium/       # æ¨ªå‘æµ·æŠ¥ (16:9)
            â”‚   â””â”€â”€ 20231210_144022/
            â”‚       â””â”€â”€ poster.png
            â”‚
            â””â”€â”€ poster_a0_academic_dense/     # A0 ç«–å‘æµ·æŠ¥ (841x1189mm)
                â””â”€â”€ 20231210_145533/
                    â””â”€â”€ poster.png
```

### æ–­ç‚¹ç»­ä¼ 
ç³»ç»Ÿè‡ªåŠ¨ä¿å­˜æ¯ä¸ªé˜¶æ®µçš„æ£€æŸ¥ç‚¹ï¼Œå¦‚æœä¸­æ–­å¯ä»¥ç»§ç»­ï¼š
```bash
# è‡ªåŠ¨ä»ä¸­æ–­å¤„ç»§ç»­
python -m paper2slides --input paper.pdf --style academic

# æˆ–æ‰‹åŠ¨æŒ‡å®šä»æŸé˜¶æ®µå¼€å§‹
python -m paper2slides --input paper.pdf --from-stage plan
```

---

## ğŸ’¡ å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šå­¦æœ¯è®ºæ–‡ â†’ ä¼šè®®æ¼”è®²å¹»ç¯ç‰‡
```bash
python -m paper2slides \
  --input research_paper.pdf \
  --output slides \
  --style academic \
  --length long            # 15-18é¡µï¼Œè¯¦ç»†è®²è§£
```

### åœºæ™¯2ï¼šè®ºæ–‡ â†’ 16:9 æ¨ªå‘æµ·æŠ¥
```bash
python -m paper2slides \
  --input paper.pdf \
  --output poster \
  --poster-format landscape \  # é»˜è®¤ï¼Œå¯çœç•¥
  --density medium \           # sparse/medium/dense
  --style doraemon \
  --fast                       # å¿«é€Ÿç”Ÿæˆ
```

### åœºæ™¯3ï¼šè®ºæ–‡ â†’ A0 ç«–å‘å­¦æœ¯æµ·æŠ¥
```bash
python -m paper2slides \
  --input paper.pdf \
  --output poster \
  --poster-format portrait_a0 \  # A0 ç«–å‘ (841mm x 1189mm)
  --density medium \
  --style academic
```

### åœºæ™¯4ï¼šæŠ€æœ¯æ–‡æ¡£ â†’ æ•™å­¦å¹»ç¯ç‰‡
```bash
python -m paper2slides \
  --input tutorial.md \
  --content general \      # é€šç”¨æ–‡æ¡£æ¨¡å¼
  --style "ç®€æ´ç°ä»£é£æ ¼ï¼Œè“ç»¿è‰²è°ƒ" \
  --length medium
```

---

# ç¬¬äºŒå±‚ï¼šæ·±å…¥ç†è§£

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

Paper2Slides é‡‡ç”¨ **ç®¡é“å¼æ¶æ„**ï¼Œå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå››ä¸ªç‹¬ç«‹é˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰ï¼š
- ğŸ“Œ **æ¸…æ™°çš„è¾“å…¥è¾“å‡º**
- ğŸ’¾ **æ£€æŸ¥ç‚¹ä¿å­˜**
- ğŸ”„ **å¯é‡å¯èƒ½åŠ›**
- âš¡ **å¹¶å‘ä¼˜åŒ–**

---

## ğŸ” å››é˜¶æ®µè¯¦è§£

### é˜¶æ®µ 1: RAG Stage - æ–‡æ¡£è§£æä¸ç´¢å¼•

**æ–‡ä»¶ä½ç½®**: `paper2slides/core/stages/rag_stage.py`

#### ä¸¤ç§å·¥ä½œæ¨¡å¼

##### Fast Modeï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
```python
# è·³è¿‡ RAG ç´¢å¼•ï¼Œç›´æ¥ç”¨ GPT-4o å¤šæ¨¡æ€åˆ†æ
def run_fast_mode(markdown_paths):
    # 1. è¯»å– Markdown æ–‡æœ¬
    # 2. æå–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
    # 3. æ„å»ºå¤šæ¨¡æ€è¾“å…¥ï¼ˆæ–‡æœ¬ + å›¾ç‰‡ï¼‰
    content_parts = [
        {"type": "text", "text": markdown_content},
        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img1}"}},
        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img2}"}},
        ...
    ]

    # 4. è°ƒç”¨ GPT-4o
    response = await openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": content_parts}]
    )
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… çŸ­æ–‡æ¡£ï¼ˆ< 20é¡µï¼‰
- âœ… å¿«é€Ÿé¢„è§ˆ
- âœ… å•æ–‡ä»¶
- âŒ ä¸é€‚åˆè¶…é•¿æ–‡æ¡£ï¼ˆToken é™åˆ¶ï¼‰

##### Normal Modeï¼ˆæ ‡å‡†æ¨¡å¼ï¼‰
```python
# å®Œæ•´ RAG æµç¨‹
def run_normal_mode(input_path):
    # 1. æ–‡æ¡£è§£æï¼ˆä½¿ç”¨ MinerUï¼‰
    parsed_files = batch_parser.process_batch([input_path])
    # è¾“å‡º: Markdown + æå–çš„å›¾ç‰‡

    # 2. æ„å»º RAG ç´¢å¼•ï¼ˆä½¿ç”¨ LightRAGï¼‰
    rag_client = RAGClient(...)
    await rag_client.index(markdown_path)
    # åˆ›å»º: å‘é‡ç´¢å¼• + çŸ¥è¯†å›¾è°±

    # 3. æ‰¹é‡æŸ¥è¯¢ï¼ˆæŒ‰ç±»åˆ«åˆ†ç»„ï¼‰
    rag_results = await rag_client.batch_query_by_category({
        "paper_info": ["è®ºæ–‡æ ‡é¢˜", "ä½œè€…", "æœºæ„"],
        "motivation": ["ç ”ç©¶é—®é¢˜", "ç°æœ‰æ–¹æ³•å±€é™"],
        "solution": ["æå‡ºæ–¹æ³•", "æ ¸å¿ƒæ¨¡å—", "ç®—æ³•æ­¥éª¤"],
        "results": ["å®éªŒæ•°æ®", "æ€§èƒ½æŒ‡æ ‡", "å¯¹æ¯”ç»“æœ"],
        ...
    })
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… é•¿æ–‡æ¡£ï¼ˆ> 20é¡µï¼‰
- âœ… å¤šæ–‡ä»¶
- âœ… éœ€è¦ç²¾ç¡®æ£€ç´¢
- âœ… æˆæœ¬æ•æ„Ÿï¼ˆRAG æ¯”ç›´æ¥ç”¨ GPT-4o ä¾¿å®œï¼‰

#### è¾“å‡ºæ ¼å¼

**checkpoint_rag.json**:
```json
{
  "rag_results": {
    "paper_info": [
      "è®ºæ–‡æ ‡é¢˜: Deep Learning for NLP\nä½œè€…: John Doe\næœºæ„: MIT"
    ],
    "motivation": [
      "ç°æœ‰æ–¹æ³•åœ¨é•¿æ–‡æœ¬å¤„ç†ä¸Šå­˜åœ¨æ•ˆç‡é—®é¢˜..."
    ],
    "solution": [
      "æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäº Transformer çš„æ–°æ¶æ„..."
    ],
    "results": [
      "åœ¨ GLUE åŸºå‡†ä¸Šè¾¾åˆ°äº† 92.3% çš„å‡†ç¡®ç‡..."
    ],
    "figures": [...],
    "tables": [...],
    ...
  },
  "markdown_paths": ["/path/to/paper.md"],
  "mode": "normal",
  "timestamp": "2023-12-10T14:30:52"
}
```

---

### é˜¶æ®µ 2: Summary Stage - å†…å®¹æå–ä¸ç»“æ„åŒ–

**æ–‡ä»¶ä½ç½®**: `paper2slides/core/stages/summary_stage.py`

#### æ ¸å¿ƒä»»åŠ¡
1. ä» RAG ç»“æœä¸­æå–ç»“æ„åŒ–å†…å®¹
2. æ¸…ç†å’Œæ ¼å¼åŒ–æ–‡æœ¬
3. æå–è¡¨æ ¼å’Œå›¾ç‰‡å…ƒä¿¡æ¯

#### å·¥ä½œæµç¨‹

```python
async def run_summary_stage(base_dir, config):
    # 1. åŠ è½½ RAG ç»“æœ
    rag_checkpoint = load_json(base_dir / "checkpoint_rag.json")
    rag_results = rag_checkpoint["rag_results"]

    # 2. é€‰æ‹©æå–å™¨
    if content_type == "paper":
        content = await extract_paper(
            rag_results=rag_results,
            llm_client=OpenAI(),
            parallel=True,         # å¹¶è¡Œæå–å„éƒ¨åˆ†
            max_concurrency=5      # æœ€å¤š 5 ä¸ªå¹¶å‘
        )
    else:
        content = await extract_general(rag_results)

    # 3. æå–è¡¨æ ¼å’Œå›¾ç‰‡
    origin = extract_tables_and_figures(markdown_paths)

    # 4. ä¿å­˜ç»“æœ
    save_json("checkpoint_summary.json", {
        "content": content.__dict__,
        "origin": origin.to_dict()
    })
```

#### æ•°æ®æ¨¡å‹

**PaperContent** (`summary/models.py:40`):
```python
@dataclass
class PaperContent:
    paper_info: str       # æ ‡é¢˜ã€ä½œè€…ã€æœºæ„ã€æ‘˜è¦
    motivation: str       # ç ”ç©¶èƒŒæ™¯ã€é—®é¢˜ã€é‡è¦æ€§
    solution: str         # æ–¹æ³•æè¿°ã€æ¶æ„ã€ç®—æ³•
    results: str          # å®éªŒè®¾ç½®ã€æ•°æ®é›†ã€ç»“æœ
    contributions: str    # ä¸»è¦è´¡çŒ®ã€åˆ›æ–°ç‚¹
```

**OriginalElements** (`summary/models.py:76`):
```python
@dataclass
class OriginalElements:
    tables: List[TableInfo]     # è¡¨æ ¼åˆ—è¡¨
    figures: List[FigureInfo]   # å›¾ç‰‡åˆ—è¡¨
    base_path: str              # åŸºç¡€è·¯å¾„

    def to_dict(self):
        return {
            "tables": [t.__dict__ for t in self.tables],
            "figures": [f.__dict__ for f in self.figures],
            "base_path": self.base_path
        }
```

#### å¹¶è¡Œæå–ç­–ç•¥

```python
# summary/paper.py:30
async def extract_paper(rag_results, llm_client, parallel=True, max_concurrency=5):
    """å¹¶è¡Œæå–è®ºæ–‡å„éƒ¨åˆ†å†…å®¹"""

    if parallel:
        # åˆ›å»ºæå–ä»»åŠ¡
        tasks = []
        for section in ["paper_info", "motivation", "solution", "results", "contributions"]:
            task = extract_section(
                section=section,
                rag_results=rag_results[section],
                llm_client=llm_client
            )
            tasks.append(task)

        # å¹¶å‘æ‰§è¡Œï¼ˆä½¿ç”¨ Semaphore æ§åˆ¶å¹¶å‘æ•°ï¼‰
        results = await asyncio.gather(*tasks)
    else:
        # é¡ºåºæ‰§è¡Œ
        results = []
        for section in sections:
            result = await extract_section(...)
            results.append(result)

    return PaperContent(*results)
```

#### è¡¨æ ¼æå–ç¤ºä¾‹

```python
# summary/extractors/table_extractor.py:15
def extract_tables(markdown_content):
    """ä» Markdown æå– HTML è¡¨æ ¼"""
    tables = []

    # 1. æŸ¥æ‰¾è¡¨æ ¼æ¨¡å¼ï¼ˆTable X: Captionï¼‰
    pattern = r'(Table\s+\d+:?\s+[^\n]+)\n\s*<table'

    for match in re.finditer(pattern, markdown_content):
        caption = match.group(1)
        table_id = extract_table_id(caption)  # "Table 1"

        # 2. æå– HTML è¡¨æ ¼å†…å®¹
        html_start = match.end()
        html_end = find_table_end(markdown_content, html_start)
        html_content = markdown_content[html_start:html_end]

        # 3. æ¸…ç†è¡¨æ ¼ï¼ˆç§»é™¤ä¸å¿…è¦çš„ HTML å±æ€§ï¼‰
        cleaned_html = clean_table_html(html_content)

        tables.append(TableInfo(
            table_id=table_id,
            caption=caption,
            html_content=cleaned_html
        ))

    return tables
```

---

### é˜¶æ®µ 3: Plan Stage - å†…å®¹è§„åˆ’

**æ–‡ä»¶ä½ç½®**: `paper2slides/core/stages/plan_stage.py`

#### æ ¸å¿ƒèŒè´£
- å†³å®šå¹»ç¯ç‰‡é¡µæ•°ï¼ˆæ ¹æ® length å‚æ•°ï¼‰æˆ–æµ·æŠ¥å†…å®¹é‡ï¼ˆæ ¹æ® density å‚æ•°ï¼‰
- åˆ†é…å†…å®¹åˆ°å„é¡µ/å„åŒºå—
- ä¸ºæ¯é¡µ/åŒºå—åŒ¹é…åˆé€‚çš„å›¾è¡¨
- æ”¯æŒä¸¤ç§æµ·æŠ¥æ ¼å¼ï¼šæ¨ªå‘ 16:9 å’Œ A0 ç«–å‘

#### å†…å®¹è§„åˆ’å™¨

**æ–‡ä»¶ä½ç½®**: `paper2slides/generator/content_planner.py:20`

```python
class ContentPlanner:
    def __init__(self, llm_client, style_type="academic"):
        self.llm_client = llm_client
        self.style_type = style_type

    def plan(self, gen_input: GenerationInput) -> ContentPlan:
        """ç”Ÿæˆå†…å®¹å¸ƒå±€æ–¹æ¡ˆï¼ˆå¹»ç¯ç‰‡æˆ–æµ·æŠ¥ï¼‰"""

        if gen_input.config.output_type == OutputType.POSTER:
            return self._plan_poster(gen_input, ...)  # æµ·æŠ¥è§„åˆ’
        else:
            return self._plan_slides(gen_input, ...)  # å¹»ç¯ç‰‡è§„åˆ’

    def _plan_poster(self, gen_input, summary, tables_md, figure_images):
        """æµ·æŠ¥å†…å®¹è§„åˆ’ï¼ˆæ”¯æŒæ¨ªå‘å’Œ A0 ç«–å‘ï¼‰"""
        density = gen_input.config.poster_density.value
        is_a0 = gen_input.config.poster_format == PosterFormat.PORTRAIT_A0

        # æ ¹æ®æ ¼å¼é€‰æ‹©å¯¹åº”çš„æç¤ºè¯æ¨¡æ¿
        if is_a0:
            template = PAPER_POSTER_A0_PLANNING_PROMPT
            layout_guidelines = PAPER_POSTER_A0_LAYOUT_GUIDELINES[density]
        else:
            template = PAPER_POSTER_PLANNING_PROMPT
            layout_guidelines = None

        # ... è°ƒç”¨ LLM è¿›è¡Œè§„åˆ’

    def _plan_slides(self, gen_input, ...):
        """å¹»ç¯ç‰‡å†…å®¹è§„åˆ’"""
        # 1. ç¡®å®šé¡µæ•°èŒƒå›´
        page_config = self._get_page_config(gen_input)
        # short: 5-8é¡µ, medium: 10-13é¡µ, long: 15-18é¡µ

        # 2. åŠ è½½å›¾ç‰‡ä¸º base64ï¼ˆç”¨äºå¤šæ¨¡æ€åˆ†æï¼‰
        figure_images = self._load_figure_images(gen_input.origin.figures)

        # 3. æ„å»ºæç¤ºè¯
        prompt = PAPER_SLIDES_PLANNING_PROMPT.format(
            min_pages=page_config["min"],
            max_pages=page_config["max"],
            summary=self._format_summary(gen_input.content),
            tables_md=self._format_tables(gen_input.origin.tables)
        )

        # 4. è°ƒç”¨ GPT-4oï¼ˆå¤šæ¨¡æ€è¾“å…¥ï¼‰
        response = self._call_multimodal_llm(
            prompt=prompt,
            images=figure_images  # è®© LLM çœ‹åˆ°æ‰€æœ‰å›¾ç‰‡
        )

        # 5. è§£æ JSON å“åº”
        plan_data = json.loads(response)
        sections = self._parse_sections(plan_data["slides"])

        return ContentPlan(sections=sections)
```

#### æç¤ºè¯ç»“æ„

**æ–‡ä»¶ä½ç½®**: `paper2slides/prompts/content_planning.py:10`

```python
PAPER_SLIDES_PLANNING_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¼”ç¤ºè®¾è®¡å¸ˆã€‚å°†ä»¥ä¸‹å­¦æœ¯è®ºæ–‡ç»„ç»‡ä¸º {min_pages}-{max_pages} é¡µå¹»ç¯ç‰‡ã€‚

## è¾“å…¥ä¿¡æ¯
- è®ºæ–‡æ‘˜è¦å’Œå„éƒ¨åˆ†å†…å®¹
- å¯ç”¨çš„è¡¨æ ¼ï¼ˆHTMLæ ¼å¼ï¼‰
- å¯ç”¨çš„å›¾ç‰‡ï¼ˆä½ å¯ä»¥çœ‹åˆ°å›¾ç‰‡å†…å®¹ï¼‰

## è¾“å‡ºè¦æ±‚

### 1. å†…å®¹åˆ†é…
- æ ‡é¢˜é¡µï¼ˆ1é¡µï¼‰ï¼šè®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€æœºæ„
- èƒŒæ™¯/åŠ¨æœºï¼ˆ1-2é¡µï¼‰ï¼šç ”ç©¶é—®é¢˜ã€ç°æœ‰æ–¹æ³•å±€é™ã€é‡è¦æ€§
- æ–¹æ³•/è§£å†³æ–¹æ¡ˆï¼ˆ3-5é¡µï¼‰ï¼š
  * æ–¹æ³•æ¦‚è§ˆï¼ˆæ¶æ„å›¾ï¼‰
  * å…³é”®æ¨¡å—è¯¦ç»†è¯´æ˜
  * æ ¸å¿ƒç®—æ³•/å…¬å¼
  * å®ç°ç»†èŠ‚
- å®éªŒ/ç»“æœï¼ˆ2-4é¡µï¼‰ï¼š
  * æ•°æ®é›†å’Œè¯„ä»·æŒ‡æ ‡
  * ä¸»è¦ç»“æœï¼ˆå¯¹æ¯”è¡¨æ ¼ï¼‰
  * æ¶ˆèå®éªŒ
  * å¯è§†åŒ–ç»“æœ
- ç»“è®ºï¼ˆ1é¡µï¼‰ï¼šè´¡çŒ®æ€»ç»“ã€æœªæ¥å·¥ä½œ

### 2. å†…å®¹è´¨é‡è¦æ±‚
å¯¹äºæ¯ä¸€é¡µçš„ `content` å­—æ®µï¼š
- **è¯¦ç»†ç¨‹åº¦**ï¼šæ¯é¡µè‡³å°‘ 150-200 è¯
- **ä¿ç•™ç»†èŠ‚**ï¼š
  * å…·ä½“æ•°å­—ï¼ˆå‡†ç¡®ç‡ 92.3%ï¼Œä¸è¦è¯´"è¶…è¿‡90%"ï¼‰
  * å…³é”®å…¬å¼ï¼ˆLaTeX æ ¼å¼ï¼‰
  * æŠ€æœ¯æœ¯è¯­ï¼ˆä¿æŒåŸæ–‡ï¼‰
  * æ­¥éª¤è¯´æ˜ï¼ˆç®—æ³•çš„æ¯ä¸ªæ­¥éª¤ï¼‰
- **ä¸è¦è¿‡åº¦ç®€åŒ–**ï¼šä»æºæ–‡æœ¬æå–å’Œæ”¹ç¼–ï¼Œä¸è¦åªå†™é«˜å±‚æ¦‚è¿°

### 3. å›¾è¡¨åŒ¹é…
ä¸ºæ¯é¡µåŒ¹é…åˆé€‚çš„å›¾è¡¨ï¼š

**tables**ï¼ˆè¡¨æ ¼åˆ—è¡¨ï¼‰ï¼š
- `table_id`: "Table 1"ï¼ˆå¼•ç”¨åŸå§‹è¡¨æ ¼IDï¼‰
- `extract`: éƒ¨åˆ†è¡¨æ ¼ HTMLï¼ˆåªåŒ…å«å…³é”®è¡Œï¼Œä¸è¦å…¨éƒ¨ï¼‰
- `focus`: åœ¨è¿™ä¸€é¡µé‡ç‚¹å…³æ³¨çš„æ–¹é¢ï¼ˆå¦‚"ä¸baselineå¯¹æ¯”"ï¼‰

**figures**ï¼ˆå›¾ç‰‡åˆ—è¡¨ï¼‰ï¼š
- `figure_id`: "Figure 1"ï¼ˆå¼•ç”¨åŸå§‹å›¾ç‰‡IDï¼‰
- `focus`: å›¾ç‰‡ä¸­é‡ç‚¹çªå‡ºçš„å†…å®¹ï¼ˆå¦‚"æ³¨æ„åŠ›æœºåˆ¶æ¨¡å—"ï¼‰

### 4. è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
{{
  "slides": [
    {{
      "id": "slide_01",
      "title": "[è®ºæ–‡æ ‡é¢˜]",
      "content": "[ä½œè€…åˆ—è¡¨åŠæœºæ„ï¼Œå®Œæ•´æ ¼å¼]",
      "tables": [],
      "figures": []
    }},
    {{
      "id": "slide_02",
      "title": "èƒŒæ™¯ä¸åŠ¨æœº",
      "content": "[è¯¦ç»†æè¿°ç ”ç©¶é—®é¢˜çš„èƒŒæ™¯ã€ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€ä¸ºä»€ä¹ˆè¿™ä¸ªé—®é¢˜é‡è¦ã€‚è‡³å°‘150è¯ï¼ŒåŒ…å«å…·ä½“ä¾‹å­å’Œæ•°æ®ã€‚]",
      "tables": [],
      "figures": [
        {{
          "figure_id": "Figure 1",
          "focus": "ç°æœ‰æ–¹æ³•çš„æ¶æ„å›¾ï¼Œçªå‡ºå…¶å±€é™æ€§"
        }}
      ]
    }},
    {{
      "id": "slide_03",
      "title": "æå‡ºæ–¹æ³•ï¼šæ•´ä½“æ¶æ„",
      "content": "[è¯¦ç»†æè¿°æ–¹æ³•çš„æ•´ä½“æ¶æ„ã€‚åŒ…å«ï¼š1ï¼‰ä¸»è¦ç»„ä»¶åŠå…¶ä½œç”¨ï¼Œ2ï¼‰ç»„ä»¶é—´çš„è¿æ¥å…³ç³»ï¼Œ3ï¼‰æ•°æ®æµå‘ã€‚è‡³å°‘200è¯ã€‚]",
      "tables": [],
      "figures": [
        {{
          "figure_id": "Figure 2",
          "focus": "æ•´ä½“æ¶æ„å›¾ï¼Œæ ‡æ³¨æ¯ä¸ªæ¨¡å—"
        }}
      ]
    }},
    ...
  ]
}}

## å½“å‰æ–‡æ¡£ä¿¡æ¯

### è®ºæ–‡å†…å®¹
{summary}

### å¯ç”¨è¡¨æ ¼
{tables_md}

### å¯ç”¨å›¾ç‰‡
[å·²ä½œä¸ºå›¾ç‰‡é™„ä»¶æä¾›ï¼Œä½ å¯ä»¥çœ‹åˆ°æ¯ä¸ªå›¾ç‰‡çš„å†…å®¹]

ç°åœ¨è¯·ç”Ÿæˆå¹»ç¯ç‰‡è§„åˆ’æ–¹æ¡ˆï¼ˆJSONæ ¼å¼ï¼‰ï¼š
"""
```

#### é¡µæ•°é…ç½®

```python
# generator/content_planner.py:80
PAGE_CONFIGS = {
    "slides": {
        "short": {"min": 5, "max": 8},
        "medium": {"min": 10, "max": 13},
        "long": {"min": 15, "max": 18}
    },
    "poster": {
        "sparse": {"pages": 1},    # æµ·æŠ¥å›ºå®š 1 é¡µ
        "medium": {"pages": 1},
        "dense": {"pages": 1}
    }
}

# A0 ç«–å‘æµ·æŠ¥å¯†åº¦é…ç½®ï¼ˆå­—æ•°æŒ‡å—ï¼‰
PAPER_POSTER_A0_LAYOUT_GUIDELINES = {
    "sparse": "~400-500 words, minimal content, focus on key points",
    "medium": "~700-900 words, balanced coverage",
    "dense": "~1000-1300 words, comprehensive content",
}
```

#### è¾“å‡ºæ ¼å¼

**checkpoint_plan.json**:
```json
{
  "sections": [
    {
      "section_id": "slide_01",
      "title": "Deep Learning for Natural Language Processing",
      "content": "Authors: John Doe (MIT), Jane Smith (Stanford)\n\nThis work addresses...",
      "tables": [],
      "figures": []
    },
    {
      "section_id": "slide_02",
      "title": "Background and Motivation",
      "content": "Natural language processing has seen remarkable progress...\n\nKey challenges:\n1. Long-range dependencies...\n2. Computational efficiency...",
      "tables": [],
      "figures": [
        {
          "figure_id": "Figure 1",
          "caption": "Comparison of existing architectures",
          "focus": "Limitations of RNN-based models",
          "image_path": "/path/to/figure_1.png",
          "mime_type": "image/png"
        }
      ]
    },
    {
      "section_id": "slide_03",
      "title": "Proposed Method: Architecture Overview",
      "content": "Our method consists of three main components:\n\n1. Multi-Head Attention Module\n   - Computes attention weights: Î± = softmax(QK^T / âˆšd_k)\n   - Enables parallel processing...\n\n2. Feed-Forward Network\n   - Two-layer MLP with ReLU activation...",
      "tables": [],
      "figures": [
        {
          "figure_id": "Figure 2",
          "caption": "Overall architecture",
          "focus": "Multi-head attention mechanism",
          "image_path": "/path/to/figure_2.png",
          "mime_type": "image/png"
        }
      ]
    },
    {
      "section_id": "slide_04",
      "title": "Experimental Results",
      "content": "We evaluate on three benchmark datasets:\n- GLUE: 92.3% average score\n- SQuAD 2.0: 88.7% F1 score\n- CoNLL 2003: 94.1% F1 score\n\nOur method outperforms...",
      "tables": [
        {
          "table_id": "Table 1",
          "caption": "Performance comparison on GLUE benchmark",
          "extract": "<table><tr><th>Model</th><th>GLUE</th></tr><tr><td>BERT</td><td>88.5</td></tr><tr><td>Ours</td><td>92.3</td></tr></table>",
          "focus": "Comparison with BERT baseline"
        }
      ],
      "figures": []
    }
  ],
  "timestamp": "2023-12-10T14:35:22"
}
```

---

### é˜¶æ®µ 4: Generate Stage - å›¾åƒç”Ÿæˆ

**æ–‡ä»¶ä½ç½®**: `paper2slides/core/stages/generate_stage.py`

#### å›¾åƒç”Ÿæˆæä¾›å•†ç³»ç»Ÿ

ç³»ç»Ÿæ”¯æŒå¤šç§å›¾åƒç”Ÿæˆæä¾›å•†ï¼Œé€šè¿‡æŠ½è±¡å·¥å‚æ¨¡å¼å®ç°çµæ´»åˆ‡æ¢ï¼š

**æ–‡ä»¶ä½ç½®**: `paper2slides/generator/providers.py`

```python
# æŠ½è±¡åŸºç±»
class ImageGenerationProvider(ABC):
    """å›¾åƒç”Ÿæˆæä¾›å•†æŠ½è±¡åŸºç±»"""

    @abstractmethod
    def generate_image(self, request: ImageGenerationRequest) -> ImageGenerationResponse:
        """ç”Ÿæˆå›¾åƒ"""
        pass

    @abstractmethod
    def get_default_model(self) -> str:
        """è·å–é»˜è®¤æ¨¡å‹å"""
        pass


# OpenRouter æä¾›å•†ï¼ˆé»˜è®¤ï¼‰
class OpenRouterProvider(ImageGenerationProvider):
    """é€šè¿‡ OpenRouter è°ƒç”¨ Gemini"""

    def __init__(
        self,
        api_key: str = None,
        base_url: str = "https://openrouter.ai/api/v1",
        model: str = "google/gemini-3-pro-image-preview"
    ):
        self.api_key = api_key or os.getenv("IMAGE_GEN_API_KEY")
        self.client = OpenAI(api_key=self.api_key, base_url=base_url)

    def generate_image(self, request):
        # ä½¿ç”¨ OpenAI å…¼å®¹ API
        response = self.client.chat.completions.create(
            model=request.model or self.default_model,
            messages=[{"role": "user", "content": content}],
            extra_body={"modalities": ["image", "text"]}
        )
        # ä» response.choices[0].message.images æå–å›¾åƒ
        ...


# Google GenAI æä¾›å•†ï¼ˆç›´è¿ï¼‰
class GoogleGenAIProvider(ImageGenerationProvider):
    """ç›´æ¥è°ƒç”¨ Google GenAI API"""

    def __init__(
        self,
        api_key: str = None,
        model: str = "gemini-3-pro-image-preview"
    ):
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")
        from google import genai
        from google.genai import types
        self.client = genai.Client(api_key=self.api_key)
        self.types = types

    def generate_image(self, request):
        # ä½¿ç”¨ Google GenAI åŸç”Ÿ API
        config = self.types.GenerateContentConfig(
            response_modalities=['TEXT', 'IMAGE'],
            image_config=self.types.ImageConfig(
                aspect_ratio="16:9",
                image_size="4K"
            )
        )
        response = self.client.models.generate_content(
            model=request.model or self.default_model,
            contents=content_parts,
            config=config
        )
        # ä» response.parts æå–å›¾åƒ
        for part in response.parts:
            image = part.as_image()
            if image:
                image.save(tmp_path)
                ...


# æä¾›å•†å·¥å‚
class ProviderFactory:
    """å›¾åƒç”Ÿæˆæä¾›å•†å·¥å‚"""

    PROVIDERS = {
        "openrouter": OpenRouterProvider,
        "google": GoogleGenAIProvider,
        "genai": GoogleGenAIProvider,  # åˆ«å
    }

    @classmethod
    def from_env(cls) -> ImageGenerationProvider:
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºæä¾›å•†"""
        provider_name = os.getenv("IMAGE_GEN_PROVIDER", "openrouter")

        if provider_name == "openrouter":
            return OpenRouterProvider(
                api_key=os.getenv("IMAGE_GEN_API_KEY"),
                model=os.getenv("IMAGE_GEN_MODEL", "google/gemini-3-pro-image-preview")
            )
        elif provider_name in ["google", "genai"]:
            return GoogleGenAIProvider(
                api_key=os.getenv("GOOGLE_API_KEY"),
                model=os.getenv("IMAGE_GEN_MODEL", "gemini-3-pro-image-preview")
            )
```

#### ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env æ–‡ä»¶é…ç½®ç¤ºä¾‹

# é€‰é¡¹ 1: ä½¿ç”¨ OpenRouterï¼ˆé»˜è®¤ï¼‰
IMAGE_GEN_PROVIDER="openrouter"
IMAGE_GEN_API_KEY="your-openrouter-api-key"
IMAGE_GEN_MODEL="google/gemini-3-pro-image-preview"

# é€‰é¡¹ 2: ä½¿ç”¨ Google GenAI ç›´è¿
IMAGE_GEN_PROVIDER="google"
GOOGLE_API_KEY="your-google-api-key"
IMAGE_GEN_MODEL="gemini-3-pro-image-preview"
```

#### æ ¸å¿ƒç­–ç•¥ï¼šæ··åˆå¹¶è¡Œç”Ÿæˆ

```python
# generator/image_generator.py:120
def _generate_slides(self, plan, gen_input, max_workers):
    """
    ç”Ÿæˆç­–ç•¥ï¼š
    1. å‰ 2 é¡µé¡ºåºç”Ÿæˆï¼ˆå»ºç«‹é£æ ¼åŸºè°ƒï¼‰
    2. ç¬¬ 2 é¡µä½œä¸ºé£æ ¼å‚è€ƒ
    3. åç»­é¡µé¢å¹¶è¡Œç”Ÿæˆï¼ˆæ‰€æœ‰é¡µé¢éƒ½å‚è€ƒç¬¬ 2 é¡µï¼‰
    """

    images = []
    style_ref_image = None
    total = len(plan.sections)

    # === é˜¶æ®µ 1: é¡ºåºç”Ÿæˆå‰ 2 é¡µ ===
    for i in range(min(2, total)):
        section = plan.sections[i]

        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(section, gen_input)

        # å‡†å¤‡å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
        section_images = self._prepare_section_images(section)

        # ç”Ÿæˆï¼ˆç¬¬1é¡µæ— å‚è€ƒï¼Œç¬¬2é¡µå‚è€ƒç¬¬1é¡µï¼‰
        if i == 0:
            image = self._call_model(prompt, section_images)
        else:
            # ç¬¬2é¡µç”Ÿæˆæ—¶ï¼Œå‚è€ƒç¬¬1é¡µ
            ref_images = [style_ref_image] if style_ref_image else []
            image = self._call_model(prompt, ref_images + section_images)

        images.append(image)

        # ä¿å­˜ç¬¬ 2 é¡µä½œä¸ºé£æ ¼å‚è€ƒ
        if i == 1:
            style_ref_image = {
                "figure_id": "Reference Slide",
                "caption": "STRICTLY MAINTAIN this exact style: " +
                           "same background color, accent colors, " +
                           "font style, layout structure, visual elements.",
                "base64": base64.b64encode(image).decode(),
                "mime_type": "image/png"
            }

    # === é˜¶æ®µ 2: å¹¶è¡Œç”Ÿæˆå‰©ä½™é¡µé¢ ===
    if total > 2:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            def generate_single(idx):
                section = plan.sections[idx]
                prompt = self._build_prompt(section, gen_input)
                section_images = self._prepare_section_images(section)

                # æ‰€æœ‰é¡µé¢éƒ½å‚è€ƒç¬¬ 2 é¡µçš„é£æ ¼
                all_images = [style_ref_image] + section_images

                return self._call_model(prompt, all_images)

            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = [
                executor.submit(generate_single, i)
                for i in range(2, total)
            ]

            # æ”¶é›†ç»“æœ
            for future in futures:
                image = future.result()
                images.append(image)

    return images
```

#### æç¤ºè¯æ„å»º

```python
# generator/image_generator.py:250
def _build_prompt(self, section, gen_input):
    """æ„å»ºå›¾åƒç”Ÿæˆæç¤ºè¯"""

    # 1. è·å–é£æ ¼æç¤º
    style_hint = self._get_style_hint()

    # 2. æ„å»ºå†…å®¹æè¿°
    content_desc = f"""
## å¹»ç¯ç‰‡å†…å®¹
æ ‡é¢˜: {section.title}

ä¸»è¦å†…å®¹:
{section.content}
"""

    # 3. è¡¨æ ¼å¤„ç†æŒ‡ä»¤
    if section.tables:
        table_instructions = """
## è¡¨æ ¼è¦æ±‚
- å°†æä¾›çš„ HTML è¡¨æ ¼å‡†ç¡®è½¬æ¢ä¸ºè§†è§‰è¡¨æ ¼
- ä¿æŒæ‰€æœ‰æ•°æ®å®Œæ•´æ€§ï¼ˆæ•°å­—ã€å•ä½ã€å°æ•°ç‚¹ï¼‰
- ä½¿ç”¨æ¸…æ™°çš„è¾¹æ¡†å’Œå¯¹é½
- é‡ç‚¹çªå‡ºï¼š{focus}
"""
        table_html = "\n\n".join([
            f"è¡¨æ ¼ {t.table_id}:\n{t.extract}"
            for t in section.tables
        ])
        content_desc += table_instructions + table_html

    # 4. å›¾ç‰‡å¤„ç†æŒ‡ä»¤
    if section.figures:
        figure_instructions = """
## å›¾ç‰‡è¦æ±‚
- å‚è€ƒæä¾›çš„åŸå§‹å›¾ç‰‡
- é‡ç»˜ä¸ºä¸å¹»ç¯ç‰‡é£æ ¼ä¸€è‡´çš„ç‰ˆæœ¬
- ä¿æŒå›¾ç‰‡çš„æ ¸å¿ƒä¿¡æ¯å’Œç»“æ„
- é‡ç‚¹çªå‡ºï¼š{focus}
"""
        content_desc += figure_instructions

    # 5. ç»„åˆå®Œæ•´æç¤ºè¯
    full_prompt = f"""
{style_hint}

{content_desc}

## æ•´ä½“è¦æ±‚
- åˆ›å»ºä¸€å¼ å®Œæ•´çš„æ¼”ç¤ºå¹»ç¯ç‰‡ï¼ˆ16:9 æ¨ªå‘ï¼‰
- é«˜åˆ†è¾¨ç‡ã€ä¸“ä¸šè´¨é‡
- å¸ƒå±€æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
- ç¡®ä¿æ–‡æœ¬å¯è¯»æ€§ï¼ˆå­—ä½“å¤§å°é€‚ä¸­ï¼‰
- ä¿æŒè§†è§‰ä¸€è‡´æ€§

ç›´æ¥è¾“å‡ºå¹»ç¯ç‰‡å›¾åƒã€‚
"""

    return full_prompt
```

#### é£æ ¼ç³»ç»Ÿ

**å†…ç½®é£æ ¼** (`prompts/image_generation.py:10`):

```python
SLIDE_STYLE_HINTS = {
    "academic": """
Professional academic presentation style.

Visual Design:
- Background: Clean white or very light gray (#f8f9fa)
- Accent Color: Navy blue (#1e3a8a) for headers and key elements
- Typography:
  * Headers: Bold sans-serif (Roboto/Inter), 48-60pt
  * Body: Regular sans-serif, 24-32pt
  * Code/Math: Monospace font
- Layout: Clear hierarchy with ample whitespace
- Decorations: Minimal geometric shapes (thin lines, subtle corners)

Content Presentation:
- Use bullet points for lists
- Tables with subtle borders
- Equations in clear LaTeX rendering
- Charts with professional color scheme
""",

    "doraemon": """
Friendly, approachable style featuring Doraemon character.

Visual Design:
- Background: Soft light blue gradient or white with blue accents
- Primary Colors: Sky blue (#0ea5e9), white, red accents
- Typography:
  * Headers: Rounded sans-serif, playful but readable
  * Body: Clean sans-serif, 24-30pt
- Decorations: Rounded corners, soft shadows
- Character Integration:
  * Doraemon appears as a guide/mascot
  * Appropriate poses for slide content
  * Don't obstruct main content

Content Presentation:
- Colorful but organized
- Use icons and visual metaphors
- Maintain professional content despite playful style
"""
}
```

**è‡ªå®šä¹‰é£æ ¼å¤„ç†** (`generator/image_generator.py:300`):

```python
def process_custom_style(llm_client, custom_style_description):
    """å°†ç”¨æˆ·è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºç»“æ„åŒ–é£æ ¼å‚æ•°"""

    prompt = f"""
åˆ†æä»¥ä¸‹å¹»ç¯ç‰‡é£æ ¼æè¿°ï¼Œæå–å…³é”®è®¾è®¡å…ƒç´ ï¼š

ç”¨æˆ·æè¿°ï¼š
{custom_style_description}

è¯·è¾“å‡º JSON æ ¼å¼çš„ç»“æ„åŒ–é£æ ¼å‚æ•°ï¼š
{{
  "style_name": "é£æ ¼åç§°ï¼ˆç®€çŸ­ï¼‰",
  "background": "èƒŒæ™¯æè¿°ï¼ˆé¢œè‰²ã€æ¸å˜ç­‰ï¼‰",
  "color_palette": "ä¸»è¦é¢œè‰²ï¼ˆè‡³å°‘3ä¸ªï¼Œå«16è¿›åˆ¶ä»£ç ï¼‰",
  "typography": "å­—ä½“é£æ ¼æè¿°",
  "decorations": "è£…é¥°å…ƒç´ æè¿°",
  "special_elements": "ç‰¹æ®Šè§†è§‰å…ƒç´ ï¼ˆå¦‚æœæœ‰ï¼‰",
  "layout_hints": "å¸ƒå±€å»ºè®®",
  "valid": true/false
}}

å¦‚æœæè¿°ä¸æ¸…æ™°æˆ–ä¸é€‚åˆå¹»ç¯ç‰‡ï¼Œè®¾ç½® valid: false å¹¶è¯´æ˜åŸå› ã€‚
"""

    response = llm_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    style_params = json.loads(response.choices[0].message.content)

    if not style_params.get("valid", False):
        raise ValueError(f"Invalid style: {style_params.get('reason', 'Unknown')}")

    return style_params
```

#### API è°ƒç”¨ï¼ˆé€šè¿‡æä¾›å•†æŠ½è±¡ï¼‰

```python
# generator/image_generator.py
class ImageGenerator:
    """ä½¿ç”¨æä¾›å•†æŠ½è±¡è¿›è¡Œå›¾åƒç”Ÿæˆ"""

    def __init__(self, provider: ImageGenerationProvider = None, model: str = None):
        # ä»ç¯å¢ƒå˜é‡è‡ªåŠ¨åˆ›å»ºæä¾›å•†
        self.provider = provider or ProviderFactory.from_env()
        self.model = model or self.provider.get_default_model()

    def _call_model(self, prompt: str, reference_images: List[dict]) -> tuple:
        """è°ƒç”¨å›¾åƒç”Ÿæˆæ¨¡å‹ï¼ˆå¸¦é‡è¯•ï¼‰"""

        # 1. åˆ›å»ºè¯·æ±‚
        request = ImageGenerationRequest(
            prompt=prompt,
            reference_images=reference_images,
            model=self.model
        )

        # 2. é‡è¯•é€»è¾‘
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # 3. è°ƒç”¨æä¾›å•†ï¼ˆè‡ªåŠ¨è·¯ç”±åˆ° OpenRouter æˆ– Google GenAIï¼‰
                response = self.provider.generate_image(request)
                return response.image_data, response.mime_type

            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(2 * (attempt + 1))
                    continue
                raise
```

#### OpenRouter è°ƒç”¨æµç¨‹

```python
# OpenRouterProvider.generate_image()
def generate_image(self, request):
    # 1. æ„å»ºæ¶ˆæ¯å†…å®¹ï¼ˆå¤šæ¨¡æ€ï¼‰
    content = [{"type": "text", "text": request.prompt}]

    # 2. æ·»åŠ å‚è€ƒå›¾ç‰‡
    for img in request.reference_images:
        content.append({
            "type": "image_url",
            "image_url": {"url": f"data:{img['mime_type']};base64,{img['base64']}"}
        })

    # 3. è°ƒç”¨ OpenRouter APIï¼ˆOpenAI å…¼å®¹æ ¼å¼ï¼‰
    response = self.client.chat.completions.create(
        model=request.model or self.default_model,
        messages=[{"role": "user", "content": content}],
        extra_body={"modalities": ["image", "text"]}
    )

    # 4. æå–å›¾åƒ
    image_url = response.choices[0].message.images[0]['image_url']['url']
    # data:image/png;base64,... æ ¼å¼
    header, base64_data = image_url.split(',', 1)
    mime_type = header.split(':')[1].split(';')[0]
    image_data = base64.b64decode(base64_data)

    return ImageGenerationResponse(image_data=image_data, mime_type=mime_type)
```

#### Google GenAI è°ƒç”¨æµç¨‹

```python
# GoogleGenAIProvider.generate_image()
def generate_image(self, request):
    # 1. æ„å»ºå†…å®¹åˆ—è¡¨
    content_parts = [request.prompt]

    # 2. æ·»åŠ å‚è€ƒå›¾ç‰‡ï¼ˆPIL Image æ ¼å¼ï¼‰
    for img in request.reference_images:
        image_bytes = base64.b64decode(img['base64'])
        pil_image = Image.open(io.BytesIO(image_bytes))
        content_parts.append(pil_image)

    # 3. é…ç½®å›¾åƒç”Ÿæˆå‚æ•°
    config = self.types.GenerateContentConfig(
        response_modalities=['TEXT', 'IMAGE'],
        image_config=self.types.ImageConfig(
            aspect_ratio="16:9",
            image_size="4K"
        )
    )

    # 4. è°ƒç”¨ Google GenAI API
    response = self.client.models.generate_content(
        model=request.model or self.default_model,
        contents=content_parts,
        config=config
    )

    # 5. ä» response.parts æå–å›¾åƒ
    for part in response.parts:
        image = part.as_image()
        if image:
            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            image.save(tmp_path)
            with open(tmp_path, 'rb') as f:
                image_data = f.read()
            return ImageGenerationResponse(image_data=image_data, mime_type="image/png")
```

---

## ğŸ§© æ ¸å¿ƒæ¨¡å—æ·±å…¥

### RAG å¼•æ“ (RAG-Anything)

**æ–‡ä»¶ä½ç½®**: `paper2slides/raganything/`

#### æ¶æ„æ¦‚è§ˆ

```
RAG-Anything = LightRAG + å¤šæ¨¡æ€å¤„ç†å™¨
```

**ç»„ä»¶**ï¼š
1. **æ–‡æ¡£è§£æå™¨** - å°†å„ç§æ ¼å¼è½¬ä¸º Markdown
2. **å¤šæ¨¡æ€å¤„ç†å™¨** - å¤„ç†æ–‡æœ¬ã€å›¾ç‰‡ã€è¡¨æ ¼
3. **å‘é‡åŒ–å¼•æ“** - æ„å»ºæ£€ç´¢ç´¢å¼•
4. **æŸ¥è¯¢å¼•æ“** - æ”¯æŒå¤šç§æ£€ç´¢æ¨¡å¼

#### æ‰¹é‡è§£æå™¨

**æ–‡ä»¶ä½ç½®**: `raganything/batch_parser.py:20`

```python
class BatchParser:
    """æ‰¹é‡æ–‡æ¡£è§£æå™¨ï¼ˆåŸºäº MinerUï¼‰"""

    def __init__(self, output_dir):
        self.output_dir = Path(output_dir)
        self.supported_formats = [".pdf", ".docx", ".pptx", ".md"]

    def process_batch(self, file_paths: List[str]) -> ParseResult:
        """
        æ‰¹é‡è§£ææ–‡æ¡£

        å·¥ä½œæµç¨‹ï¼š
        1. éªŒè¯æ–‡ä»¶æ ¼å¼
        2. è°ƒç”¨ MinerU CLI è¿›è¡Œè§£æ
        3. æ”¶é›†è§£æç»“æœï¼ˆMarkdown + å›¾ç‰‡ï¼‰
        4. è¿”å›æˆåŠŸ/å¤±è´¥åˆ—è¡¨
        """

        # 1. è¿‡æ»¤æœ‰æ•ˆæ–‡ä»¶
        valid_files = [
            f for f in file_paths
            if Path(f).suffix.lower() in self.supported_formats
        ]

        # 2. è°ƒç”¨ MinerU
        command = [
            "magic-pdf",
            "-p", ",".join(valid_files),
            "-o", str(self.output_dir),
            "-m", "auto"  # è‡ªåŠ¨æ¨¡å¼ï¼ˆOCR + å¸ƒå±€åˆ†æï¼‰
        ]

        result = subprocess.run(
            command,
            capture_output=True,
            text=True,
            timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
        )

        # 3. è§£æè¾“å‡º
        if result.returncode == 0:
            # æ£€æŸ¥ç”Ÿæˆçš„ Markdown æ–‡ä»¶
            markdown_files = list(self.output_dir.glob("**/*.md"))

            return ParseResult(
                successful_files=markdown_files,
                failed_files=[],
                output_dir=self.output_dir
            )
        else:
            return ParseResult(
                successful_files=[],
                failed_files=valid_files,
                error=result.stderr
            )
```

#### RAG å®¢æˆ·ç«¯

**æ–‡ä»¶ä½ç½®**: `rag/client.py:30`

```python
class RAGClient:
    """RAG å®¢æˆ·ç«¯ï¼ˆå°è£… LightRAGï¼‰"""

    def __init__(self, working_dir, llm_config):
        self.working_dir = Path(working_dir)
        self.llm_config = llm_config
        self.rag = None  # LightRAG å®ä¾‹

    @classmethod
    def from_storage(cls, storage_dir):
        """ä»å·²æœ‰å­˜å‚¨ç›®å½•åŠ è½½"""
        # æ£€æŸ¥å­˜å‚¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = [
            "kv_store_full_docs.json",
            "kv_store_text_chunks.json",
            "graph_chunk_entity_relation.graphml"
        ]

        for file in required_files:
            if not (storage_dir / file).exists():
                raise FileNotFoundError(f"Missing: {file}")

        # åˆå§‹åŒ– LightRAG
        rag = LightRAG(working_dir=str(storage_dir), ...)

        client = cls(storage_dir, llm_config)
        client.rag = rag
        return client

    async def index(self, file_path: str):
        """
        ç´¢å¼•æ–‡æ¡£

        æµç¨‹ï¼š
        1. è¯»å– Markdown æ–‡æœ¬
        2. åˆ†å—ï¼ˆChunkingï¼‰
        3. å‘é‡åŒ–ï¼ˆEmbeddingï¼‰
        4. æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆEntity + Relationsï¼‰
        5. å­˜å‚¨åˆ°ç£ç›˜
        """

        # 1. è¯»å–å†…å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # 2. ç´¢å¼•ï¼ˆLightRAG å†…éƒ¨å¤„ç†ï¼‰
        await self.rag.ainsert(content)

        logger.info(f"Indexed: {file_path}")

    async def query(self, question: str, mode: str = "mix") -> str:
        """
        æŸ¥è¯¢

        mode é€‰é¡¹ï¼š
        - local: å±€éƒ¨æ£€ç´¢ï¼ˆåŸºäºå‘é‡ç›¸ä¼¼åº¦ï¼‰
        - global: å…¨å±€æ£€ç´¢ï¼ˆåŸºäºå›¾è°±ï¼‰
        - hybrid: æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + å›¾è°±ï¼‰
        - mix: è‡ªé€‚åº”æ··åˆï¼ˆæ¨èï¼‰
        """

        answer = await self.rag.aquery(question, param=QueryParam(mode=mode))
        return answer

    async def batch_query_by_category(
        self,
        queries_by_category: Dict[str, List[str]],
        max_concurrency: int = 8
    ) -> Dict[str, List[str]]:
        """
        æŒ‰ç±»åˆ«æ‰¹é‡æŸ¥è¯¢ï¼ˆå¹¶å‘æ§åˆ¶ï¼‰

        ç¤ºä¾‹è¾“å…¥ï¼š
        {
            "paper_info": ["è®ºæ–‡æ ‡é¢˜", "ä½œè€…", "æœºæ„"],
            "motivation": ["ç ”ç©¶é—®é¢˜", "ç°æœ‰æ–¹æ³•å±€é™"],
            ...
        }

        è¾“å‡ºï¼š
        {
            "paper_info": ["æ ‡é¢˜: ...", "ä½œè€…: ...", "æœºæ„: ..."],
            "motivation": ["é—®é¢˜: ...", "å±€é™: ..."],
            ...
        }
        """

        results = {}

        for category, questions in queries_by_category.items():
            # ä½¿ç”¨ Semaphore æ§åˆ¶å¹¶å‘æ•°
            semaphore = asyncio.Semaphore(max_concurrency)

            async def query_one(q):
                async with semaphore:
                    return await self.query(q)

            # å¹¶å‘æŸ¥è¯¢
            answers = await asyncio.gather(*[
                query_one(q) for q in questions
            ])

            results[category] = answers

        return results
```

#### é¢„å®šä¹‰æŸ¥è¯¢æ¨¡æ¿

**æ–‡ä»¶ä½ç½®**: `rag/query.py:10`

```python
RAG_PAPER_QUERIES = {
    "paper_info": [
        "è®ºæ–‡çš„å®Œæ•´æ ‡é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ",
        "è°æ˜¯è¿™ç¯‡è®ºæ–‡çš„ä½œè€…ï¼Ÿåˆ—å‡ºæ‰€æœ‰ä½œè€…å§“åã€‚",
        "ä½œè€…æ¥è‡ªå“ªäº›æœºæ„æˆ–å¤§å­¦ï¼Ÿ",
        "è®ºæ–‡çš„æ‘˜è¦æˆ–æ¦‚è¿°æ˜¯ä»€ä¹ˆï¼Ÿ"
    ],

    "motivation": [
        "è¿™ç¯‡è®ºæ–‡è¦è§£å†³ä»€ä¹ˆç ”ç©¶é—®é¢˜æˆ–æŒ‘æˆ˜ï¼Ÿ",
        "ç°æœ‰æ–¹æ³•æœ‰å“ªäº›å±€é™æ€§æˆ–ä¸è¶³ï¼Ÿ",
        "ä¸ºä»€ä¹ˆè¿™ä¸ªç ”ç©¶é—®é¢˜å¾ˆé‡è¦ï¼Ÿæœ‰ä»€ä¹ˆåº”ç”¨ä»·å€¼ï¼Ÿ",
        "è®ºæ–‡åœ¨å¼•è¨€ä¸­æåˆ°äº†å“ªäº›ç›¸å…³å·¥ä½œï¼Ÿ"
    ],

    "solution": [
        "è®ºæ–‡æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æŠ€æœ¯ï¼Ÿ",
        "æ–¹æ³•çš„æ•´ä½“æ¶æ„æˆ–æ¡†æ¶æ˜¯ä»€ä¹ˆï¼Ÿæè¿°ä¸»è¦ç»„ä»¶ã€‚",
        "æœ‰å“ªäº›å…³é”®çš„ç®—æ³•æ­¥éª¤æˆ–æµç¨‹ï¼Ÿ",
        "æ–¹æ³•ä¸­ä½¿ç”¨äº†å“ªäº›æ ¸å¿ƒå…¬å¼æˆ–æ•°å­¦æ¨¡å‹ï¼Ÿ",
        "æœ‰å“ªäº›æŠ€æœ¯ç»†èŠ‚æˆ–å®ç°è¦ç‚¹ï¼Ÿ"
    ],

    "results": [
        "è®ºæ–‡åœ¨å“ªäº›æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Ÿ",
        "ä½¿ç”¨äº†å“ªäº›è¯„ä»·æŒ‡æ ‡ï¼Ÿ",
        "ä¸»è¦çš„å®éªŒç»“æœæ˜¯ä»€ä¹ˆï¼ŸåŒ…æ‹¬å…·ä½“æ•°å­—å’Œå¯¹æ¯”ã€‚",
        "ä¸baselineæ–¹æ³•ç›¸æ¯”ï¼Œæ€§èƒ½æå‡äº†å¤šå°‘ï¼Ÿ",
        "è¿›è¡Œäº†å“ªäº›æ¶ˆèå®éªŒï¼ŸéªŒè¯äº†ä»€ä¹ˆï¼Ÿ"
    ],

    "figures": [
        "å›¾1å±•ç¤ºäº†ä»€ä¹ˆå†…å®¹ï¼Ÿè¯¦ç»†æè¿°ã€‚",
        "æœ‰å“ªäº›æ¶æ„å›¾æˆ–æµç¨‹å›¾ï¼Ÿå®ƒä»¬æ˜¾ç¤ºäº†ä»€ä¹ˆï¼Ÿ",
        "æœ‰å“ªäº›å¯è§†åŒ–ç»“æœå›¾ï¼Ÿå®ƒä»¬å±•ç¤ºäº†ä»€ä¹ˆè¶‹åŠ¿æˆ–æ¨¡å¼ï¼Ÿ"
    ],

    "tables": [
        "è¡¨1åŒ…å«ä»€ä¹ˆæ•°æ®ï¼Ÿåˆ—å‡ºå…³é”®æ•°å€¼ã€‚",
        "æœ‰å“ªäº›æ€§èƒ½å¯¹æ¯”è¡¨ï¼Ÿæ¯”è¾ƒäº†å“ªäº›æ–¹æ³•ï¼Ÿ",
        "æœ‰å“ªäº›æ¶ˆèå®éªŒè¡¨ï¼ŸéªŒè¯äº†å“ªäº›ç»„ä»¶çš„ä½œç”¨ï¼Ÿ"
    ],

    "contributions": [
        "è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ç›¸æ¯”å·²æœ‰å·¥ä½œï¼Œè®ºæ–‡çš„åˆ›æ–°ç‚¹åœ¨å“ªé‡Œï¼Ÿ",
        "è®ºæ–‡çš„å±€é™æ€§æ˜¯ä»€ä¹ˆï¼Ÿæœªæ¥å·¥ä½œæ–¹å‘ï¼Ÿ"
    ]
}
```

---

### Web API æœåŠ¡

**æ–‡ä»¶ä½ç½®**: `api/server.py`

#### æœåŠ¡å™¨æ¶æ„

```python
from fastapi import FastAPI, File, UploadFile, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

app = FastAPI(title="Paper2Slides API")

# CORS é…ç½®ï¼ˆå…è®¸å‰ç«¯è®¿é—®ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # Vite é»˜è®¤ç«¯å£
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)

# é™æ€æ–‡ä»¶æœåŠ¡
app.mount("/outputs", StaticFiles(directory="outputs"), name="outputs")
app.mount("/uploads", StaticFiles(directory="sources/uploads"), name="uploads")

# å…¨å±€çŠ¶æ€
app.state.results = {}            # {session_id: result}
app.state.session_manager = SessionManager()
```

#### ä¼šè¯ç®¡ç†å™¨

```python
class SessionManager:
    """
    å…¨å±€ä¼šè¯ç®¡ç†å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    é™åˆ¶ï¼šåŒæ—¶åªèƒ½è¿è¡Œä¸€ä¸ªç”Ÿæˆä»»åŠ¡
    """

    def __init__(self):
        self.running_session = None
        self.cancelled_sessions = set()
        self.lock = asyncio.Lock()

    async def start_session(self, session_id: str) -> bool:
        """å°è¯•å¯åŠ¨ä¼šè¯"""
        async with self.lock:
            if self.running_session is not None:
                logger.warning(f"Session {session_id} blocked: {self.running_session} is running")
                return False

            self.running_session = session_id
            logger.info(f"Session {session_id} started")
            return True

    async def end_session(self, session_id: str):
        """ç»“æŸä¼šè¯"""
        async with self.lock:
            if self.running_session == session_id:
                self.running_session = None
                logger.info(f"Session {session_id} ended")

    async def cancel_session(self, session_id: str):
        """å–æ¶ˆä¼šè¯"""
        self.cancelled_sessions.add(session_id)
        logger.info(f"Session {session_id} marked for cancellation")

    def is_cancelled(self, session_id: str) -> bool:
        """æ£€æŸ¥ä¼šè¯æ˜¯å¦å·²å–æ¶ˆ"""
        return session_id in self.cancelled_sessions

    def is_running(self) -> bool:
        """æ˜¯å¦æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œ"""
        return self.running_session is not None
```

#### æ ¸å¿ƒç«¯ç‚¹å®ç°

##### 1. ä¸Šä¼ å’Œå¯åŠ¨

```python
@app.post("/api/chat")
async def chat(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(...),
    content: str = Form("paper"),
    output_type: str = Form("slides"),
    style: str = Form("academic"),
    slides_length: str = Form("medium"),
    poster_density: str = Form("medium"),
    poster_format: str = Form("landscape"),  # landscape æˆ– portrait_a0
    fast_mode: bool = Form(False),
    session_id: Optional[str] = Form(None)
):
    """
    å¤„ç†ç”¨æˆ·è¯·æ±‚

    å·¥ä½œæµç¨‹ï¼š
    1. æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œï¼ˆäº’æ–¥é”ï¼‰
    2. åˆ›å»ºä¼šè¯ ID
    3. ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    4. åå°å¯åŠ¨æµæ°´çº¿
    5. ç«‹å³è¿”å› session_id
    """

    # 1. æ£€æŸ¥ä»»åŠ¡è¿è¡ŒçŠ¶æ€
    if session_manager.is_running():
        raise HTTPException(
            status_code=429,
            detail="Another task is running. Please wait."
        )

    # 2. åˆ›å»ºä¼šè¯
    if not session_id:
        session_id = str(uuid.uuid4())

    # 3. ä¿å­˜æ–‡ä»¶
    session_dir = UPLOAD_DIR / session_id
    session_dir.mkdir(parents=True, exist_ok=True)

    file_paths = []
    for file in files:
        file_path = session_dir / file.filename
        with open(file_path, "wb") as f:
            shutil.copyfileobj(file.file, f)
        file_paths.append(str(file_path))

    # 4. æ„å»ºé…ç½®
    config = {
        "content_type": content,
        "output_type": output_type,
        "style": style,
        "slides_length": slides_length,
        "poster_density": poster_density,
        "poster_format": poster_format,  # æµ·æŠ¥æ ¼å¼ï¼šlandscape æˆ– portrait_a0
        "fast_mode": fast_mode
    }

    # 5. åå°å¯åŠ¨æµæ°´çº¿
    background_tasks.add_task(
        run_pipeline_background,
        session_id,
        file_paths,
        config
    )

    # 6. è¿”å›
    return {
        "session_id": session_id,
        "uploaded_files": [f.filename for f in files],
        "message": "Generation started"
    }
```

##### 2. åå°ä»»åŠ¡

```python
async def run_pipeline_background(
    session_id: str,
    input_files: List[str],
    config: dict
):
    """åå°è¿è¡Œæµæ°´çº¿"""

    try:
        # 1. è·å–ä¼šè¯é”
        success = await session_manager.start_session(session_id)
        if not success:
            logger.error(f"Failed to start session {session_id}")
            return

        # 2. è¿è¡Œæµæ°´çº¿
        logger.info(f"Starting pipeline for session {session_id}")

        result = await generate_slides_with_pipeline(
            input_path=input_files[0] if len(input_files) == 1 else input_files,
            config=config,
            session_id=session_id,
            session_manager=session_manager
        )

        # 3. ä¿å­˜ç»“æœåˆ°å†…å­˜ç¼“å­˜
        app.state.results[session_id] = {
            "status": "completed",
            "result": result,
            "timestamp": datetime.now().isoformat()
        }

        logger.info(f"Pipeline completed for session {session_id}")

    except Exception as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·å–æ¶ˆ
        if session_manager.is_cancelled(session_id):
            app.state.results[session_id] = {
                "status": "cancelled",
                "error": "Task cancelled by user"
            }
        else:
            # å…¶ä»–é”™è¯¯
            logger.error(f"Pipeline failed for session {session_id}: {e}")
            app.state.results[session_id] = {
                "status": "failed",
                "error": str(e)
            }

    finally:
        # 4. é‡Šæ”¾ä¼šè¯é”
        await session_manager.end_session(session_id)


async def generate_slides_with_pipeline(
    input_path,
    config,
    session_id,
    session_manager
):
    """å®é™…æ‰§è¡Œæµæ°´çº¿"""

    # 1. ç¡®å®šè·¯å¾„
    project_name = get_project_name(input_path)
    base_dir = get_base_dir("outputs", project_name, config["content_type"])
    config_dir = get_config_dir(base_dir, config)

    # 2. æ£€æµ‹èµ·å§‹é˜¶æ®µï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    from_stage = detect_start_stage(base_dir, config_dir, config)

    # 3. è¿è¡Œæµæ°´çº¿
    await run_pipeline(
        base_dir=base_dir,
        config_dir=config_dir,
        config=config,
        from_stage=from_stage,
        session_id=session_id,
        session_manager=session_manager
    )

    # 4. æ”¶é›†è¾“å‡ºæ–‡ä»¶
    output_dir = find_latest_output_dir(config_dir)
    slides = []

    for png_file in sorted(output_dir.glob("slide_*.png")):
        slides.append({
            "title": f"Slide {png_file.stem.split('_')[1]}",
            "image_url": f"/outputs/{png_file.relative_to('outputs')}"
        })

    pdf_path = output_dir / "slides.pdf"
    pdf_url = f"/outputs/{pdf_path.relative_to('outputs')}" if pdf_path.exists() else None

    return {
        "slides": slides,
        "pdf_url": pdf_url
    }
```

##### 3. çŠ¶æ€æŸ¥è¯¢

```python
@app.get("/api/status/{session_id}")
async def get_status(session_id: str):
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€

    è¿”å›ï¼š
    - status: running, completed, failed, cancelled
    - stages: å„é˜¶æ®µçŠ¶æ€
    - progress: è¿›åº¦ä¿¡æ¯
    """

    # 1. ä»ç£ç›˜è¯»å–çŠ¶æ€æ–‡ä»¶
    state_file = find_state_file(session_id)

    if not state_file:
        # æ£€æŸ¥å†…å­˜ç¼“å­˜
        if session_id in app.state.results:
            return app.state.results[session_id]

        raise HTTPException(status_code=404, detail="Session not found")

    # 2. è§£æçŠ¶æ€
    with open(state_file, 'r') as f:
        state = json.load(f)

    # 3. åˆ¤æ–­æ•´ä½“çŠ¶æ€
    stages = state.get("stages", {})

    if all(s == "completed" for s in stages.values()):
        overall_status = "completed"
    elif any(s == "failed" for s in stages.values()):
        overall_status = "failed"
    elif any(s == "running" for s in stages.values()):
        overall_status = "running"
    else:
        overall_status = "pending"

    return {
        "status": overall_status,
        "stages": stages,
        "timestamp": state.get("timestamp")
    }
```

##### 4. ç»“æœè·å–

```python
@app.get("/api/result/{session_id}")
async def get_result(session_id: str):
    """è·å–ç”Ÿæˆç»“æœ"""

    # 1. æ£€æŸ¥ç¼“å­˜
    if session_id not in app.state.results:
        raise HTTPException(status_code=404, detail="Result not found")

    cached = app.state.results[session_id]

    # 2. æ£€æŸ¥çŠ¶æ€
    if cached["status"] != "completed":
        raise HTTPException(
            status_code=400,
            detail=f"Task is {cached['status']}"
        )

    # 3. è¿”å›ç»“æœ
    return cached["result"]
```

##### 5. å–æ¶ˆä»»åŠ¡

```python
@app.post("/api/cancel/{session_id}")
async def cancel_task(session_id: str):
    """å–æ¶ˆä»»åŠ¡"""

    # æ ‡è®°ä¸ºå–æ¶ˆï¼ˆæµæ°´çº¿ä¼šå®šæœŸæ£€æŸ¥ï¼‰
    await session_manager.cancel_session(session_id)

    return {"message": f"Cancellation requested for session {session_id}"}
```

---

### å‰ç«¯ç•Œé¢

**æ–‡ä»¶ä½ç½®**: `frontend/src/`

#### ä¸»åº”ç”¨ç»„ä»¶

**App.jsx**:
```jsx
import { useState, useEffect } from 'react'
import ChatWindow from './components/ChatWindow'
import ConfigPanel from './components/ConfigPanel'
import FileUpload from './components/FileUpload'

function App() {
  const [sessionId, setSessionId] = useState(null)
  const [status, setStatus] = useState('idle')  // idle, uploading, processing, completed
  const [config, setConfig] = useState({
    content: 'paper',
    outputType: 'slides',
    style: 'academic',
    length: 'medium',
    fastMode: false
  })

  // ä¸Šä¼ æ–‡ä»¶
  const handleFileUpload = async (files) => {
    setStatus('uploading')

    const formData = new FormData()
    files.forEach(file => formData.append('files', file))
    formData.append('content', config.content)
    formData.append('output_type', config.outputType)
    formData.append('style', config.style)
    formData.append('slides_length', config.length)
    formData.append('fast_mode', config.fastMode)

    try {
      const response = await fetch('http://localhost:8001/api/chat', {
        method: 'POST',
        body: formData
      })

      const data = await response.json()
      setSessionId(data.session_id)
      setStatus('processing')

      // å¼€å§‹è½®è¯¢çŠ¶æ€
      startPolling(data.session_id)

    } catch (error) {
      console.error('Upload failed:', error)
      setStatus('error')
    }
  }

  // è½®è¯¢çŠ¶æ€
  const startPolling = (sid) => {
    const interval = setInterval(async () => {
      try {
        const response = await fetch(`http://localhost:8001/api/status/${sid}`)
        const data = await response.json()

        if (data.status === 'completed') {
          clearInterval(interval)
          setStatus('completed')
          loadResults(sid)
        } else if (data.status === 'failed') {
          clearInterval(interval)
          setStatus('error')
        }

      } catch (error) {
        console.error('Polling error:', error)
      }
    }, 2000)  // æ¯ 2 ç§’è½®è¯¢ä¸€æ¬¡
  }

  // åŠ è½½ç»“æœ
  const loadResults = async (sid) => {
    try {
      const response = await fetch(`http://localhost:8001/api/result/${sid}`)
      const data = await response.json()

      // æ˜¾ç¤ºç»“æœ...

    } catch (error) {
      console.error('Load results error:', error)
    }
  }

  return (
    <div className="app">
      <ConfigPanel config={config} onChange={setConfig} />
      <FileUpload onUpload={handleFileUpload} />
      <ChatWindow sessionId={sessionId} status={status} />
    </div>
  )
}
```

---

## ğŸ› ï¸ å·¥å…·å’Œè¾…åŠ©æ¨¡å—

### è·¯å¾„å·¥å…·

**æ–‡ä»¶ä½ç½®**: `paper2slides/core/paths.py`

```python
def get_project_name(input_path):
    """ä»è¾“å…¥è·¯å¾„æå–é¡¹ç›®å"""
    if isinstance(input_path, list):
        input_path = input_path[0]

    return Path(input_path).stem  # ä¸å«æ‰©å±•åçš„æ–‡ä»¶å


def get_base_dir(output_dir, project_name, content_type):
    """è·å–åŸºç¡€è¾“å‡ºç›®å½•"""
    # outputs/{project_name}/{content_type}/{mode}/
    return Path(output_dir) / project_name / content_type


def get_config_name(config):
    """ç”Ÿæˆé…ç½®ç›®å½•å"""
    output_type = config["output_type"]
    style = config.get("style", "academic")

    if output_type == "poster":
        param = config.get("poster_density", "medium")
        # A0 ç«–å‘æµ·æŠ¥ä½¿ç”¨ poster_a0 å‰ç¼€
        poster_format = config.get("poster_format", "landscape")
        if poster_format == "portrait_a0":
            return f"poster_a0_{style}_{param}"  # poster_a0_academic_medium
        return f"poster_{style}_{param}"  # poster_academic_medium
    else:
        param = config.get("slides_length", "medium")
        return f"{output_type}_{style}_{param}"  # slides_doraemon_medium


def get_config_dir(base_dir, config):
    """è·å–é…ç½®ç‰¹å®šç›®å½•"""
    mode = "fast" if config.get("fast_mode") else "normal"
    config_name = get_config_name(config)

    # outputs/{project}/{content}/{mode}/{config}/
    return base_dir / mode / config_name


def get_timestamped_output_dir(config_dir):
    """è·å–æ—¶é—´æˆ³è¾“å‡ºç›®å½•"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return config_dir / timestamp
```

### çŠ¶æ€ç®¡ç†

**æ–‡ä»¶ä½ç½®**: `paper2slides/core/state.py`

```python
def create_initial_state():
    """åˆ›å»ºåˆå§‹çŠ¶æ€"""
    return {
        "stages": {
            "rag": "pending",
            "summary": "pending",
            "plan": "pending",
            "generate": "pending"
        },
        "timestamp": datetime.now().isoformat(),
        "version": "1.0"
    }


def save_state(config_dir, state):
    """ä¿å­˜çŠ¶æ€åˆ°ç£ç›˜"""
    state_file = config_dir / "state.json"
    config_dir.mkdir(parents=True, exist_ok=True)

    with open(state_file, 'w') as f:
        json.dump(state, f, indent=2)


def load_state(config_dir):
    """ä»ç£ç›˜åŠ è½½çŠ¶æ€"""
    state_file = config_dir / "state.json"

    if not state_file.exists():
        return create_initial_state()

    with open(state_file, 'r') as f:
        return json.load(f)


def detect_start_stage(base_dir, config_dir, config):
    """æ™ºèƒ½æ£€æµ‹èµ·å§‹é˜¶æ®µ"""
    mode = "fast" if config.get("fast_mode") else "normal"
    mode_dir = base_dir / mode

    # æ£€æŸ¥å„é˜¶æ®µæ£€æŸ¥ç‚¹
    checkpoints = {
        "rag": mode_dir / "checkpoint_rag.json",
        "summary": mode_dir / "checkpoint_summary.json",
        "plan": config_dir / "checkpoint_plan.json"
    }

    # ä»åå¾€å‰æ£€æŸ¥
    if checkpoints["plan"].exists():
        return "generate"  # åªéœ€é‡æ–°ç”Ÿæˆ

    if checkpoints["summary"].exists():
        return "plan"  # ä»è§„åˆ’å¼€å§‹

    if checkpoints["rag"].exists():
        return "summary"  # ä»æå–å¼€å§‹

    return "rag"  # ä»å¤´å¼€å§‹
```

---

## ğŸ“Š æ•°æ®æµç¤ºæ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF æ–‡ä»¶   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MinerU è§£æ                         â”‚
â”‚ - æå–æ–‡æœ¬                          â”‚
â”‚ - æå–å›¾ç‰‡                          â”‚
â”‚ - è¯†åˆ«è¡¨æ ¼                          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Markdown + Images                   â”‚
â”‚ paper.md                            â”‚
â”‚ images/                             â”‚
â”‚   â”œâ”€ figure_1.png                   â”‚
â”‚   â””â”€ figure_2.png                   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Fast Mode
       â”‚            (ç›´æ¥ç”¨ GPT-4o)
       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Normal Mode
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ LightRAG ç´¢å¼•       â”‚
           â”‚ - æ–‡æœ¬å‘é‡åŒ–        â”‚
           â”‚ - çŸ¥è¯†å›¾è°±æ„å»º      â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ æ‰¹é‡æŸ¥è¯¢            â”‚
           â”‚ {category: answers} â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                     â”‚
       â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG ç»“æœ    â”‚      â”‚ Markdown    â”‚
â”‚ checkpoint_ â”‚      â”‚ åŸæ–‡        â”‚
â”‚ rag.json    â”‚      â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ å†…å®¹æå–            â”‚
           â”‚ - æå–å„éƒ¨åˆ†        â”‚
           â”‚ - æå–è¡¨æ ¼/å›¾ç‰‡     â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ ç»“æ„åŒ–å†…å®¹          â”‚
           â”‚ checkpoint_         â”‚
           â”‚ summary.json        â”‚
           â”‚ - PaperContent      â”‚
           â”‚ - OriginalElements  â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ å†…å®¹è§„åˆ’            â”‚
           â”‚ (GPT-4o å¤šæ¨¡æ€)     â”‚
           â”‚ - ç¡®å®šé¡µæ•°          â”‚
           â”‚ - åˆ†é…å†…å®¹          â”‚
           â”‚ - åŒ¹é…å›¾è¡¨          â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ å†…å®¹æ–¹æ¡ˆ            â”‚
           â”‚ checkpoint_         â”‚
           â”‚ plan.json           â”‚
           â”‚ - sections[]        â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ å›¾åƒç”Ÿæˆ            â”‚
           â”‚ (Gemini 3 Pro)      â”‚
           â”‚ - å‰2é¡µé¡ºåº         â”‚
           â”‚ - åç»­å¹¶è¡Œ          â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ æœ€ç»ˆè¾“å‡º            â”‚
           â”‚ slide_01.png        â”‚
           â”‚ slide_02.png        â”‚
           â”‚ ...                 â”‚
           â”‚ slides.pdf          â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ç¬¬ä¸‰å±‚ï¼šé«˜çº§å¼€å‘

## ğŸš€ æ‰©å±•å’Œå®šåˆ¶

### 1. æµ·æŠ¥æ ¼å¼ç³»ç»Ÿï¼ˆå·²å®ç°ï¼‰

ç³»ç»Ÿå·²æ”¯æŒä¸¤ç§æµ·æŠ¥æ ¼å¼ï¼š**æ¨ªå‘ 16:9** å’Œ **A0 ç«–å‘å­¦æœ¯æµ·æŠ¥**ã€‚

#### é…ç½®å®šä¹‰

```python
# generator/config.py

class PosterFormat(str, Enum):
    """æµ·æŠ¥æ ¼å¼é€‰é¡¹"""
    LANDSCAPE = "landscape"     # 16:9 æ¨ªå‘ï¼ˆé»˜è®¤ï¼‰
    PORTRAIT_A0 = "portrait_a0" # A0 ç«–å‘ (841mm x 1189mm)

# A0 æµ·æŠ¥å°ºå¯¸å¸¸é‡
POSTER_A0_DIMENSIONS = {
    "width_mm": 841,
    "height_mm": 1189,
    "aspect_ratio": "9:13",  # è¿‘ä¼¼ç«–å‘æ¯”ä¾‹
    "dpi": 300,
}

@dataclass
class GenerationConfig:
    output_type: OutputType = OutputType.POSTER
    poster_density: PosterDensity = PosterDensity.MEDIUM
    poster_format: PosterFormat = PosterFormat.LANDSCAPE  # æ–°å¢
    slides_length: SlidesLength = SlidesLength.MEDIUM
    style: StyleType = StyleType.ACADEMIC
    custom_style: Optional[str] = None

    def is_portrait_poster(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º A0 ç«–å‘æµ·æŠ¥"""
        return (self.output_type == OutputType.POSTER and
                self.poster_format == PosterFormat.PORTRAIT_A0)
```

#### A0 æµ·æŠ¥æç¤ºè¯æ¨¡æ¿

```python
# prompts/image_generation.py

FORMAT_POSTER_A0 = """PORTRAIT A0 academic conference poster (aspect ratio approximately 2:3 vertical, like 841mm width x 1189mm height).
Generate ONE complete vertical poster image. The poster should be TALLER than it is wide.
This is a professional academic conference poster with structured layout."""

POSTER_A0_STYLE_HINTS = {
    "academic": """Professional academic conference poster style for A0 PORTRAIT format.

LAYOUT STRUCTURE (Top to Bottom):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      TITLE BAR (colored)        â”‚  â† Title, authors, affiliations, logos
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  LEFT   â”‚ â”‚ CENTER  â”‚       â”‚  â† 2-3 column layout for content
â”‚  â”‚ COLUMN  â”‚ â”‚ COLUMN  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   RESULTS SECTION   â”‚       â”‚  â† Wide section for tables/figures
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚    CONCLUSIONS      â”‚       â”‚  â† Bottom section
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STYLE REQUIREMENTS:
- Background: Clean white or very light gray
- Title bar: Navy blue with white text
- Typography: Professional sans-serif
- Colors: LIMITED PALETTE (3-4 colors max)
- English text only""",

    "doraemon": """Doraemon-themed academic poster style for A0 PORTRAIT format.
Story-based layout with problem â†’ solution â†’ results flow.
SOPHISTICATED Doraemon palette - NOT childish colors.""",
}

# æŒ‰å¯†åº¦çš„å¸ƒå±€æ¨¡æ¿
POSTER_A0_LAYOUTS = {
    "sparse": "Title + 2 columns + 1-2 figures + 3-4 bullet conclusion",
    "medium": "Title + 3 columns + full results section + 5-6 contributions",
    "dense": "Complete header + 3 detailed columns + multiple tables + full analysis",
}
```

#### å†…å®¹è§„åˆ’æç¤ºè¯

```python
# prompts/content_planning.py

PAPER_POSTER_A0_PLANNING_PROMPT = """Organize the document into sections for a PORTRAIT A0 academic poster (841mm x 1189mm, vertical layout).

## Required Sections for A0 Poster (in order):
1. **header**: Paper title, ALL authors with affiliations
2. **introduction**: Background, problem statement, motivation
3. **method**: Proposed approach with key components and formulas
4. **results**: Experimental evaluation with tables and figures
5. **conclusion**: Main contributions and takeaways

## Output Format (JSON)
{
  "sections": [
    {"id": "header", "title": "[Paper Title]", "content": "[Authors]", ...},
    {"id": "introduction", "title": "Introduction & Motivation", ...},
    {"id": "method", "title": "[Method Name]", ...},
    {"id": "results", "title": "Experiments & Results", ...},
    {"id": "conclusion", "title": "Conclusions", ...}
  ]
}
"""

# å¯†åº¦å¯¹åº”çš„å¸ƒå±€æŒ‡å—
PAPER_POSTER_A0_LAYOUT_GUIDELINES = {
    "sparse": "~400-500 words, minimal content",
    "medium": "~700-900 words, balanced content",
    "dense": "~1000-1300 words, comprehensive content",
}
```

#### ContentPlanner æ›´æ–°

```python
# generator/content_planner.py

def _plan_poster(self, gen_input, summary, tables_md, figure_images):
    """Plan poster sections (landscape or portrait A0)."""
    density = gen_input.config.poster_density.value
    is_a0 = gen_input.config.poster_format == PosterFormat.PORTRAIT_A0

    if gen_input.is_paper():
        density_guidelines = PAPER_POSTER_DENSITY_GUIDELINES[density]
        if is_a0:
            template = PAPER_POSTER_A0_PLANNING_PROMPT
            layout_guidelines = PAPER_POSTER_A0_LAYOUT_GUIDELINES[density]
        else:
            template = PAPER_POSTER_PLANNING_PROMPT
            layout_guidelines = None
    # ... ç±»ä¼¼å¤„ç† general content

    prompt = template.format(
        density_guidelines=density_guidelines,
        layout_guidelines=layout_guidelines,
        summary=summary,
        assets_section=assets_section,
    )

    result = self._call_multimodal_llm(prompt, figure_images)
    return self._parse_sections(result, is_slides=False)
```

#### ImageGenerator æ›´æ–°

```python
# generator/image_generator.py

def _generate_poster(self, style_name, processed_style, sections_md, images,
                     poster_format=PosterFormat.LANDSCAPE, density="medium"):
    """Generate 1 poster image (landscape 16:9 or portrait A0)."""
    is_a0 = poster_format == PosterFormat.PORTRAIT_A0

    if is_a0:
        prompt = self._build_poster_a0_prompt(
            style_name=style_name,
            processed_style=processed_style,
            sections_md=sections_md,
            density=density,
        )
    else:
        prompt = self._build_poster_prompt(
            format_prefix=FORMAT_POSTER,
            style_name=style_name,
            processed_style=processed_style,
            sections_md=sections_md,
        )

    image_data, mime_type = self._call_model(prompt, images)
    return [GeneratedImage(section_id="poster", image_data=image_data, mime_type=mime_type)]

def _build_poster_a0_prompt(self, style_name, processed_style, sections_md, density):
    """Build prompt for A0 portrait poster."""
    parts = [FORMAT_POSTER_A0]

    # ä½¿ç”¨ A0 ä¸“ç”¨æ ·å¼æç¤º
    style_hints = POSTER_A0_STYLE_HINTS.get(style_name, POSTER_A0_STYLE_HINTS["academic"])
    parts.append(style_hints)

    # æ·»åŠ å¯†åº¦å¯¹åº”çš„å¸ƒå±€æŒ‡å—
    layout_guide = POSTER_A0_LAYOUTS.get(density, POSTER_A0_LAYOUTS["medium"])
    parts.append(layout_guide)

    parts.append(VISUALIZATION_HINTS)
    parts.append(POSTER_FIGURE_HINT)
    parts.append(f"---\nContent:\n{sections_md}")

    return "\n\n".join(parts)
```

#### ä½¿ç”¨ç¤ºä¾‹

```bash
# ç”Ÿæˆ A0 ç«–å‘å­¦æœ¯æµ·æŠ¥
python -m paper2slides --input paper.pdf --output poster --poster-format portrait_a0 --style academic --density medium

# ç”Ÿæˆ A0 ç«–å‘ Doraemon é£æ ¼æµ·æŠ¥
python -m paper2slides --input paper.pdf --output poster --poster-format portrait_a0 --style doraemon --density dense

# ç”Ÿæˆé»˜è®¤æ¨ªå‘æµ·æŠ¥ï¼ˆå‘åå…¼å®¹ï¼‰
python -m paper2slides --input paper.pdf --output poster --style academic
```

#### è¾“å‡ºç›®å½•ç»“æ„

ç³»ç»Ÿæ ¹æ®æµ·æŠ¥æ ¼å¼ç”Ÿæˆä¸åŒçš„ç›®å½•åï¼š

```
outputs/
â”œâ”€â”€ paper_name/
â”‚   â””â”€â”€ paper/
â”‚       â””â”€â”€ normal/
â”‚           â”œâ”€â”€ poster_academic_medium/          # æ¨ªå‘æµ·æŠ¥
â”‚           â”‚   â””â”€â”€ 20241210_143022/
â”‚           â”‚       â””â”€â”€ poster.png
â”‚           â””â”€â”€ poster_a0_academic_medium/       # A0 ç«–å‘æµ·æŠ¥
â”‚               â””â”€â”€ 20241210_144533/
â”‚                   â””â”€â”€ poster.png
```

---

### 2. è‡ªå®šä¹‰ RAG æŸ¥è¯¢ç­–ç•¥

**ç›®æ ‡**ï¼šé’ˆå¯¹ç‰¹å®šå­¦ç§‘ï¼ˆå¦‚è®¡ç®—æœºè§†è§‰è®ºæ–‡ï¼‰ä¼˜åŒ–æŸ¥è¯¢

#### åˆ›å»ºä¸“ç”¨æŸ¥è¯¢æ¨¡æ¿

```python
# rag/query.py
RAG_CV_PAPER_QUERIES = {
    "paper_info": [
        "è®ºæ–‡çš„å®Œæ•´æ ‡é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ä½œè€…åŠæœºæ„ä¿¡æ¯ï¼Ÿ",
        "å‘è¡¨åœ¨å“ªä¸ªä¼šè®®æˆ–æœŸåˆŠï¼Ÿ"
    ],

    "motivation": [
        "è¦è§£å†³è®¡ç®—æœºè§†è§‰ä¸­çš„ä»€ä¹ˆé—®é¢˜ï¼Ÿ",
        "ç°æœ‰ CV æ–¹æ³•çš„å±€é™æ€§ï¼Ÿ",
        "åœ¨å“ªäº›å…·ä½“åœºæ™¯æˆ–æ•°æ®é›†ä¸Šå­˜åœ¨æŒ‘æˆ˜ï¼Ÿ"
    ],

    "architecture": [
        "æå‡ºäº†ä»€ä¹ˆç½‘ç»œæ¶æ„ï¼Ÿ",
        "æ¶æ„åŒ…å«å“ªäº›æ¨¡å—ï¼ˆBackbone, Neck, Headï¼‰ï¼Ÿ",
        "ä½¿ç”¨äº†å“ªäº›æ³¨æ„åŠ›æœºåˆ¶æˆ–ç‰¹å¾èåˆæ–¹æ³•ï¼Ÿ",
        "æ¨¡å‹çš„è¾“å…¥è¾“å‡ºæ˜¯ä»€ä¹ˆï¼Ÿ"
    ],

    "training": [
        "ä½¿ç”¨äº†å“ªäº›æŸå¤±å‡½æ•°ï¼Ÿ",
        "è®­ç»ƒç­–ç•¥æ˜¯ä»€ä¹ˆï¼ˆå­¦ä¹ ç‡ã€ä¼˜åŒ–å™¨ã€æ•°æ®å¢å¼ºï¼‰ï¼Ÿ",
        "é¢„è®­ç»ƒæ¨¡å‹æˆ–æƒé‡åˆå§‹åŒ–æ–¹å¼ï¼Ÿ"
    ],

    "datasets": [
        "åœ¨å“ªäº›æ•°æ®é›†ä¸Šè¯„ä¼°ï¼ˆCOCO, ImageNet, ADE20Kç­‰ï¼‰ï¼Ÿ",
        "æ•°æ®é›†çš„è§„æ¨¡å’Œç‰¹ç‚¹ï¼Ÿ",
        "æ•°æ®é¢„å¤„ç†æˆ–åå¤„ç†æ­¥éª¤ï¼Ÿ"
    ],

    "results": [
        "ä¸»è¦è¯„ä»·æŒ‡æ ‡ï¼ˆmAP, IoU, Accuracyç­‰ï¼‰åŠæ•°å€¼ï¼Ÿ",
        "ä¸ SOTA æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼Ÿ",
        "æ¶ˆèå®éªŒéªŒè¯äº†å“ªäº›è®¾è®¡é€‰æ‹©ï¼Ÿ",
        "æ¨ç†é€Ÿåº¦å’Œæ¨¡å‹å¤§å°ï¼Ÿ"
    ],

    "visualizations": [
        "æœ‰å“ªäº›å¯è§†åŒ–ç»“æœï¼ˆæ£€æµ‹æ¡†ã€åˆ†å‰²æ©ç ã€æ³¨æ„åŠ›å›¾ï¼‰ï¼Ÿ",
        "å®šæ€§åˆ†æå±•ç¤ºäº†ä»€ä¹ˆï¼Ÿ"
    ]
}
```

#### æ³¨å†ŒæŸ¥è¯¢ç­–ç•¥

```python
# rag/client.py
class RAGClient:
    QUERY_STRATEGIES = {
        "paper_general": RAG_PAPER_QUERIES,
        "paper_cv": RAG_CV_PAPER_QUERIES,
        "paper_nlp": RAG_NLP_PAPER_QUERIES,  # å¯æ‰©å±•
        "general_doc": RAG_GENERAL_QUERIES
    }

    def __init__(self, ..., query_strategy="paper_general"):
        self.query_strategy = query_strategy
        self.queries = self.QUERY_STRATEGIES[query_strategy]

    async def query_all_categories(self):
        """ä½¿ç”¨å½“å‰ç­–ç•¥æŸ¥è¯¢æ‰€æœ‰ç±»åˆ«"""
        return await self.batch_query_by_category(self.queries)
```

#### è‡ªåŠ¨æ£€æµ‹å­¦ç§‘

```python
# summary/paper.py
def detect_paper_domain(rag_results):
    """è‡ªåŠ¨æ£€æµ‹è®ºæ–‡é¢†åŸŸ"""

    keywords_map = {
        "cv": ["image", "vision", "detection", "segmentation", "CNN", "ResNet"],
        "nlp": ["language", "text", "BERT", "transformer", "embedding"],
        "ml": ["learning", "optimization", "gradient", "model"],
        "rl": ["reinforcement", "agent", "policy", "reward"]
    }

    # ä» paper_info å’Œ motivation æå–å…³é”®è¯
    text = " ".join(rag_results.get("paper_info", []) +
                    rag_results.get("motivation", []))
    text_lower = text.lower()

    # è®¡ç®—åŒ¹é…åˆ†æ•°
    scores = {}
    for domain, keywords in keywords_map.items():
        scores[domain] = sum(1 for kw in keywords if kw.lower() in text_lower)

    # è¿”å›æœ€é«˜åˆ†çš„é¢†åŸŸ
    best_domain = max(scores, key=scores.get)

    if scores[best_domain] >= 3:  # è‡³å°‘ 3 ä¸ªå…³é”®è¯åŒ¹é…
        return best_domain
    else:
        return "general"
```

---

### 3. ä¼˜åŒ–å›¾åƒç”Ÿæˆè´¨é‡

#### ç­–ç•¥ 1ï¼šè¿­ä»£æ”¹è¿›

```python
# generator/image_generator.py
class ImageGenerator:
    def generate_with_refinement(self, section, gen_input, max_iterations=2):
        """è¿­ä»£æ”¹è¿›ç”Ÿæˆè´¨é‡"""

        # ç¬¬ä¸€æ¬¡ç”Ÿæˆ
        image_v1 = self._generate_single(section, gen_input)

        if max_iterations == 1:
            return image_v1

        # æå–æ–‡æœ¬è¿›è¡ŒéªŒè¯
        extracted_text = self._extract_text_from_image(image_v1)
        expected_text = self._extract_key_terms(section.content)

        # æ£€æŸ¥å…³é”®ä¿¡æ¯æ˜¯å¦å®Œæ•´
        missing = self._find_missing_elements(extracted_text, expected_text)

        if not missing:
            return image_v1  # å·²ç»å®Œç¾

        # ç¬¬äºŒæ¬¡ç”Ÿæˆï¼ˆå¸¦åé¦ˆï¼‰
        refinement_prompt = f"""
å‰ä¸€ç‰ˆæœ¬ç¼ºå¤±æˆ–ä¸æ¸…æ™°çš„å†…å®¹ï¼š
{missing}

è¯·ç”Ÿæˆæ”¹è¿›ç‰ˆæœ¬ï¼Œç¡®ä¿åŒ…å«æ‰€æœ‰å…³é”®ä¿¡æ¯ã€‚
"""

        image_v2 = self._generate_single(
            section,
            gen_input,
            additional_prompt=refinement_prompt,
            reference_image=image_v1  # ä½œä¸ºå‚è€ƒ
        )

        return image_v2

    def _extract_text_from_image(self, image_bytes):
        """ä½¿ç”¨ OCR æå–å›¾ç‰‡ä¸­çš„æ–‡æœ¬"""
        # ä½¿ç”¨ GPT-4o vision æˆ– Tesseract OCR
        pass

    def _find_missing_elements(self, extracted, expected):
        """æ£€æŸ¥ç¼ºå¤±çš„å…³é”®å…ƒç´ """
        missing = []

        for key_term in expected:
            if key_term not in extracted:
                missing.append(key_term)

        return missing
```

#### ç­–ç•¥ 2ï¼šé£æ ¼è¿ç§»

```python
class StyleTransferGenerator(ImageGenerator):
    """åŸºäºå‚è€ƒå›¾ç‰‡çš„é£æ ¼è¿ç§»ç”Ÿæˆå™¨"""

    def __init__(self, ..., style_reference_image):
        super().__init__(...)
        self.style_reference = self._load_style_reference(style_reference_image)

    def _build_prompt(self, section, gen_input):
        base_prompt = super()._build_prompt(section, gen_input)

        # æ·»åŠ é£æ ¼è¿ç§»æŒ‡ä»¤
        style_prompt = f"""
å‚è€ƒå›¾ç‰‡å±•ç¤ºäº†ç›®æ ‡é£æ ¼ã€‚è¯·ä¸¥æ ¼éµå¾ªå‚è€ƒå›¾ç‰‡çš„ï¼š
- é…è‰²æ–¹æ¡ˆï¼ˆç²¾ç¡®çš„é¢œè‰²ä»£ç ï¼‰
- å­—ä½“é£æ ¼å’Œå¤§å°
- å¸ƒå±€ç»“æ„å’Œè¾¹è·
- è£…é¥°å…ƒç´ çš„ä½ç½®å’Œå½¢çŠ¶
- æ•´ä½“è§†è§‰é£æ ¼

åŒæ—¶ç”¨æ–°å†…å®¹æ›¿æ¢å‚è€ƒå›¾ç‰‡ä¸­çš„æ–‡å­—å’Œæ•°æ®ã€‚
"""

        return base_prompt + "\n\n" + style_prompt

    def _generate_single(self, section, gen_input):
        prompt = self._build_prompt(section, gen_input)
        images = [self.style_reference] + self._prepare_section_images(section)

        return self._call_model(prompt, images)
```

#### ç­–ç•¥ 3ï¼šåˆ†è¾¨ç‡æå‡

```python
def upscale_image(image_bytes, target_width=3840, target_height=2160):
    """æå‡å›¾åƒåˆ†è¾¨ç‡ï¼ˆ4Kï¼‰"""

    from PIL import Image
    import io

    # 1. åŠ è½½å›¾ç‰‡
    img = Image.open(io.BytesIO(image_bytes))

    # 2. ä½¿ç”¨é«˜è´¨é‡é‡é‡‡æ ·
    upscaled = img.resize(
        (target_width, target_height),
        resample=Image.LANCZOS  # é«˜è´¨é‡æ’å€¼
    )

    # 3. æˆ–ä½¿ç”¨ AI è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼ˆReal-ESRGANï¼‰
    # upscaled = ai_upscale(img, scale=2)

    # 4. ä¿å­˜
    output = io.BytesIO()
    upscaled.save(output, format='PNG', quality=95)

    return output.getvalue()


# é›†æˆåˆ°ç”Ÿæˆæµç¨‹
class ImageGenerator:
    def generate_slides(self, plan, gen_input):
        # ç”ŸæˆåŸå§‹å›¾ç‰‡
        images = self._generate_all(plan, gen_input)

        # æå‡åˆ†è¾¨ç‡
        if gen_input.config.get("high_resolution", False):
            images = [upscale_image(img) for img in images]

        return images
```

---

### 4. æ€§èƒ½ä¼˜åŒ–

#### ä¼˜åŒ– 1ï¼šç¼“å­˜æœºåˆ¶

```python
# core/cache.py
import hashlib
import pickle

class ResultCache:
    """ç»“æœç¼“å­˜ï¼ˆé¿å…é‡å¤ç”Ÿæˆï¼‰"""

    def __init__(self, cache_dir=".cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)

    def get_cache_key(self, data):
        """ç”Ÿæˆç¼“å­˜é”®ï¼ˆåŸºäºå†…å®¹å“ˆå¸Œï¼‰"""
        serialized = pickle.dumps(data)
        hash_value = hashlib.sha256(serialized).hexdigest()
        return hash_value[:16]

    def get(self, key):
        """è·å–ç¼“å­˜"""
        cache_file = self.cache_dir / f"{key}.pkl"

        if cache_file.exists():
            with open(cache_file, 'rb') as f:
                return pickle.load(f)

        return None

    def set(self, key, value):
        """è®¾ç½®ç¼“å­˜"""
        cache_file = self.cache_dir / f"{key}.pkl"

        with open(cache_file, 'wb') as f:
            pickle.dump(value, f)


# åœ¨ RAG é˜¶æ®µä½¿ç”¨
cache = ResultCache()

async def run_rag_stage_with_cache(base_dir, config):
    # ç”Ÿæˆç¼“å­˜é”®
    cache_key = cache.get_cache_key({
        "input_files": config["input_path"],
        "mode": config.get("fast_mode", False),
        "queries": RAG_PAPER_QUERIES
    })

    # æ£€æŸ¥ç¼“å­˜
    cached_result = cache.get(cache_key)
    if cached_result:
        logger.info("Using cached RAG results")
        return cached_result

    # æ‰§è¡Œ RAG
    result = await run_rag_stage(base_dir, config)

    # ä¿å­˜ç¼“å­˜
    cache.set(cache_key, result)

    return result
```

#### ä¼˜åŒ– 2ï¼šæ‰¹é‡å¤„ç†

```python
# api/server.py
class BatchProcessor:
    """æ‰¹é‡å¤„ç†å¤šä¸ªä»»åŠ¡"""

    def __init__(self, max_batch_size=5, max_wait_time=10):
        self.max_batch_size = max_batch_size
        self.max_wait_time = max_wait_time
        self.pending_tasks = []
        self.lock = asyncio.Lock()

    async def add_task(self, session_id, files, config):
        """æ·»åŠ ä»»åŠ¡åˆ°æ‰¹æ¬¡"""
        async with self.lock:
            self.pending_tasks.append({
                "session_id": session_id,
                "files": files,
                "config": config,
                "added_at": time.time()
            })

            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‰¹æ¬¡å¤§å°æˆ–ç­‰å¾…æ—¶é—´
            if len(self.pending_tasks) >= self.max_batch_size:
                await self._process_batch()
            else:
                # å¯åŠ¨å®šæ—¶å™¨
                asyncio.create_task(self._wait_and_process())

    async def _wait_and_process(self):
        """ç­‰å¾…å¹¶å¤„ç†æ‰¹æ¬¡"""
        await asyncio.sleep(self.max_wait_time)

        async with self.lock:
            if self.pending_tasks:
                await self._process_batch()

    async def _process_batch(self):
        """æ‰¹é‡å¤„ç†ä»»åŠ¡"""
        if not self.pending_tasks:
            return

        batch = self.pending_tasks.copy()
        self.pending_tasks.clear()

        logger.info(f"Processing batch of {len(batch)} tasks")

        # å¹¶è¡Œå¤„ç†ï¼ˆå…±äº« RAG ç´¢å¼•ï¼‰
        tasks = [
            self._process_single(task)
            for task in batch
        ]

        await asyncio.gather(*tasks)

    async def _process_single(self, task):
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        try:
            await run_pipeline_background(
                task["session_id"],
                task["files"],
                task["config"]
            )
        except Exception as e:
            logger.error(f"Task {task['session_id']} failed: {e}")
```

#### ä¼˜åŒ– 3ï¼šèµ„æºé™åˆ¶

```python
# core/pipeline.py
import psutil
import asyncio

class ResourceMonitor:
    """èµ„æºç›‘æ§å™¨"""

    def __init__(self, max_memory_percent=80, max_cpu_percent=90):
        self.max_memory_percent = max_memory_percent
        self.max_cpu_percent = max_cpu_percent

    def check_resources(self):
        """æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ"""
        memory = psutil.virtual_memory()
        cpu = psutil.cpu_percent(interval=1)

        if memory.percent > self.max_memory_percent:
            raise ResourceWarning(f"Memory usage too high: {memory.percent}%")

        if cpu > self.max_cpu_percent:
            raise ResourceWarning(f"CPU usage too high: {cpu}%")

        return {
            "memory_percent": memory.percent,
            "cpu_percent": cpu,
            "available_memory_gb": memory.available / (1024**3)
        }

    async def wait_for_resources(self, timeout=300):
        """ç­‰å¾…èµ„æºå¯ç”¨"""
        start_time = time.time()

        while time.time() - start_time < timeout:
            try:
                self.check_resources()
                return True
            except ResourceWarning:
                logger.warning("Resources exhausted, waiting...")
                await asyncio.sleep(10)

        raise TimeoutError("Resources not available within timeout")


# åœ¨æµæ°´çº¿ä¸­ä½¿ç”¨
monitor = ResourceMonitor()

async def run_pipeline(base_dir, config_dir, config, from_stage):
    for stage in STAGES:
        # æ£€æŸ¥èµ„æº
        await monitor.wait_for_resources()

        # æ‰§è¡Œé˜¶æ®µ
        await run_stage(stage)
```

---

### 5. æ·»åŠ æ–°çš„å›¾åƒç”Ÿæˆæä¾›å•†

**ç›®æ ‡**ï¼šæ·»åŠ æ–°çš„å›¾åƒç”Ÿæˆ APIï¼ˆå¦‚ Stability AIã€DALL-E ç­‰ï¼‰

ç³»ç»Ÿå·²å®ç°æä¾›å•†æŠ½è±¡ï¼Œæ·»åŠ æ–°æä¾›å•†åªéœ€å®ç° `ImageGenerationProvider` æ¥å£ã€‚

#### æ­¥éª¤ 1ï¼šå®ç°æä¾›å•†ç±»

```python
# generator/providers.py

class StabilityAIProvider(ImageGenerationProvider):
    """Stability AI æä¾›å•†ç¤ºä¾‹"""

    def __init__(self, api_key: str = None, model: str = "stable-diffusion-xl"):
        self.api_key = api_key or os.getenv("STABILITY_API_KEY")
        self.default_model = model

        if not self.api_key:
            raise ValueError("Stability AI API key is required")

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        import stability_sdk
        self.client = stability_sdk.Client(api_key=self.api_key)

    def get_default_model(self) -> str:
        return self.default_model

    def generate_image(self, request: ImageGenerationRequest) -> ImageGenerationResponse:
        """ç”Ÿæˆå›¾åƒ"""
        # æ„å»ºè¯·æ±‚
        # æ³¨æ„ï¼šä¸åŒ API å¯èƒ½ä¸æ”¯æŒå‚è€ƒå›¾ç‰‡
        result = self.client.generate(
            prompt=request.prompt,
            model=request.model or self.default_model
        )

        # æå–å›¾åƒ
        image_data = result.images[0].bytes
        mime_type = "image/png"

        return ImageGenerationResponse(image_data=image_data, mime_type=mime_type)
```

#### æ­¥éª¤ 2ï¼šæ³¨å†Œåˆ°å·¥å‚

```python
# generator/providers.py

class ProviderFactory:
    PROVIDERS = {
        "openrouter": OpenRouterProvider,
        "google": GoogleGenAIProvider,
        "genai": GoogleGenAIProvider,
        "stability": StabilityAIProvider,  # æ–°å¢
    }

    @classmethod
    def from_env(cls) -> ImageGenerationProvider:
        provider_name = os.getenv("IMAGE_GEN_PROVIDER", "openrouter").lower()

        if provider_name == "stability":
            return StabilityAIProvider(
                api_key=os.getenv("STABILITY_API_KEY"),
                model=os.getenv("IMAGE_GEN_MODEL", "stable-diffusion-xl")
            )
        # ... å…¶ä»–æä¾›å•†
```

#### æ­¥éª¤ 3ï¼šæ›´æ–°é…ç½®æ–‡æ¡£

```bash
# .env.example æ·»åŠ 

# --- Stability AI Provider Settings ---
# Required when IMAGE_GEN_PROVIDER="stability"
# STABILITY_API_KEY=""
# IMAGE_GEN_MODEL="stable-diffusion-xl"
```

#### æ­¥éª¤ 4ï¼šæ·»åŠ æµ‹è¯•

```python
# tests/test_providers.py

def test_stability_provider():
    """æµ‹è¯• Stability AI æä¾›å•†"""
    api_key = os.getenv("STABILITY_API_KEY")
    if not api_key:
        pytest.skip("STABILITY_API_KEY not set")

    provider = StabilityAIProvider(api_key=api_key)

    request = ImageGenerationRequest(
        prompt="A simple test image",
        reference_images=[]
    )

    response = provider.generate_image(request)
    assert response.image_data
    assert response.mime_type == "image/png"
```

---

### 6. æ·»åŠ æ–°çš„æ–‡æœ¬ LLM æä¾›å•†

**ç›®æ ‡**ï¼šæ”¯æŒ Anthropic Claude ä½œä¸ºæ–‡æœ¬æ¨¡å‹

#### æ­¥éª¤ 1ï¼šåˆ›å»ºå®¢æˆ·ç«¯é€‚é…å™¨

```python
# llm/providers.py
from abc import ABC, abstractmethod

class LLMProvider(ABC):
    """LLM æä¾›å•†æŠ½è±¡åŸºç±»"""

    @abstractmethod
    async def chat(self, messages, model, **kwargs):
        """èŠå¤©è¡¥å…¨"""
        pass

    @abstractmethod
    async def embed(self, texts, model):
        """æ–‡æœ¬åµŒå…¥"""
        pass


class OpenAIProvider(LLMProvider):
    """OpenAI æä¾›å•†"""

    def __init__(self, api_key, base_url=None):
        from openai import AsyncOpenAI
        self.client = AsyncOpenAI(api_key=api_key, base_url=base_url)

    async def chat(self, messages, model="gpt-4o", **kwargs):
        response = await self.client.chat.completions.create(
            model=model,
            messages=messages,
            **kwargs
        )
        return response.choices[0].message.content

    async def embed(self, texts, model="text-embedding-3-large"):
        response = await self.client.embeddings.create(
            model=model,
            input=texts
        )
        return [item.embedding for item in response.data]


class ClaudeProvider(LLMProvider):
    """Anthropic Claude æä¾›å•†"""

    def __init__(self, api_key):
        from anthropic import AsyncAnthropic
        self.client = AsyncAnthropic(api_key=api_key)

    async def chat(self, messages, model="claude-3-opus-20240229", **kwargs):
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼ï¼ˆOpenAI â†’ Claudeï¼‰
        claude_messages = self._convert_messages(messages)

        response = await self.client.messages.create(
            model=model,
            messages=claude_messages,
            max_tokens=kwargs.get("max_tokens", 4096)
        )

        return response.content[0].text

    def _convert_messages(self, openai_messages):
        """è½¬æ¢æ¶ˆæ¯æ ¼å¼"""
        claude_messages = []

        for msg in openai_messages:
            if msg["role"] == "system":
                # Claude ä½¿ç”¨å•ç‹¬çš„ system å‚æ•°
                continue

            claude_messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })

        return claude_messages

    async def embed(self, texts, model=None):
        # Claude ä¸ç›´æ¥æä¾›åµŒå…¥ï¼Œä½¿ç”¨ Voyage AI
        raise NotImplementedError("Use Voyage AI for embeddings")
```

#### æ­¥éª¤ 2ï¼šæä¾›å•†å·¥å‚

```python
# llm/factory.py
class LLMFactory:
    """LLM æä¾›å•†å·¥å‚"""

    PROVIDERS = {
        "openai": OpenAIProvider,
        "claude": ClaudeProvider,
        "gemini": GeminiProvider,  # å¯æ‰©å±•
    }

    @classmethod
    def create(cls, provider_name, **config):
        """åˆ›å»ºæä¾›å•†å®ä¾‹"""
        if provider_name not in cls.PROVIDERS:
            raise ValueError(f"Unknown provider: {provider_name}")

        provider_class = cls.PROVIDERS[provider_name]
        return provider_class(**config)

    @classmethod
    def from_config(cls, config_file=".env"):
        """ä»é…ç½®æ–‡ä»¶åˆ›å»º"""
        import os
        from dotenv import load_dotenv

        load_dotenv(config_file)

        provider = os.getenv("LLM_PROVIDER", "openai")

        if provider == "openai":
            return cls.create("openai",
                api_key=os.getenv("OPENAI_API_KEY"),
                base_url=os.getenv("OPENAI_BASE_URL")
            )
        elif provider == "claude":
            return cls.create("claude",
                api_key=os.getenv("ANTHROPIC_API_KEY")
            )
        else:
            raise ValueError(f"Unsupported provider: {provider}")
```

#### æ­¥éª¤ 3ï¼šé›†æˆåˆ°ä»£ç ä¸­

```python
# åœ¨å„æ¨¡å—ä¸­ä½¿ç”¨
# summary/paper.py
async def extract_paper(rag_results, llm_provider=None, **kwargs):
    if llm_provider is None:
        llm_provider = LLMFactory.from_config()

    # ä½¿ç”¨ç»Ÿä¸€æ¥å£
    response = await llm_provider.chat(
        messages=[{"role": "user", "content": "..."}],
        model="gpt-4o-mini",  # è‡ªåŠ¨æ˜ å°„åˆ° Claude æ¨¡å‹
        max_tokens=4000
    )

    return response


# é…ç½®æ–‡ä»¶ (.env)
# LLM_PROVIDER=claude
# ANTHROPIC_API_KEY=your_key
```

---

### 7. è‡ªå®šä¹‰åå¤„ç†

#### åå¤„ç†å™¨æ¡†æ¶

```python
# generator/postprocessors.py
from abc import ABC, abstractmethod

class Postprocessor(ABC):
    """åå¤„ç†å™¨æŠ½è±¡åŸºç±»"""

    @abstractmethod
    def process(self, image_bytes):
        """å¤„ç†å›¾ç‰‡"""
        pass


class WatermarkPostprocessor(Postprocessor):
    """æ·»åŠ æ°´å°"""

    def __init__(self, watermark_text="Generated by Paper2Slides", position="bottom-right"):
        self.watermark_text = watermark_text
        self.position = position

    def process(self, image_bytes):
        from PIL import Image, ImageDraw, ImageFont
        import io

        # 1. åŠ è½½å›¾ç‰‡
        img = Image.open(io.BytesIO(image_bytes))
        draw = ImageDraw.Draw(img)

        # 2. åŠ è½½å­—ä½“
        try:
            font = ImageFont.truetype("Arial.ttf", 24)
        except:
            font = ImageFont.load_default()

        # 3. è®¡ç®—ä½ç½®
        text_bbox = draw.textbbox((0, 0), self.watermark_text, font=font)
        text_width = text_bbox[2] - text_bbox[0]
        text_height = text_bbox[3] - text_bbox[1]

        if self.position == "bottom-right":
            x = img.width - text_width - 20
            y = img.height - text_height - 20
        # ... å…¶ä»–ä½ç½®

        # 4. ç»˜åˆ¶æ°´å°
        draw.text((x, y), self.watermark_text, fill=(128, 128, 128, 128), font=font)

        # 5. ä¿å­˜
        output = io.BytesIO()
        img.save(output, format='PNG')

        return output.getvalue()


class BorderPostprocessor(Postprocessor):
    """æ·»åŠ è¾¹æ¡†"""

    def __init__(self, border_width=10, border_color=(200, 200, 200)):
        self.border_width = border_width
        self.border_color = border_color

    def process(self, image_bytes):
        from PIL import Image, ImageOps
        import io

        img = Image.open(io.BytesIO(image_bytes))

        # æ·»åŠ è¾¹æ¡†
        img_with_border = ImageOps.expand(
            img,
            border=self.border_width,
            fill=self.border_color
        )

        output = io.BytesIO()
        img_with_border.save(output, format='PNG')

        return output.getvalue()


class CompressionPostprocessor(Postprocessor):
    """å‹ç¼©å›¾ç‰‡"""

    def __init__(self, quality=85, max_size_mb=5):
        self.quality = quality
        self.max_size_mb = max_size_mb

    def process(self, image_bytes):
        from PIL import Image
        import io

        img = Image.open(io.BytesIO(image_bytes))

        # å‹ç¼©
        output = io.BytesIO()
        img.save(output, format='PNG', optimize=True, quality=self.quality)

        # æ£€æŸ¥å¤§å°
        size_mb = len(output.getvalue()) / (1024 * 1024)

        if size_mb > self.max_size_mb:
            # è¿›ä¸€æ­¥å‹ç¼©
            scale = (self.max_size_mb / size_mb) ** 0.5
            new_size = (int(img.width * scale), int(img.height * scale))
            img = img.resize(new_size, Image.LANCZOS)

            output = io.BytesIO()
            img.save(output, format='PNG', optimize=True, quality=self.quality)

        return output.getvalue()


class PostprocessorPipeline:
    """åå¤„ç†æµæ°´çº¿"""

    def __init__(self, processors):
        self.processors = processors

    def process(self, image_bytes):
        """ä¾æ¬¡åº”ç”¨æ‰€æœ‰åå¤„ç†å™¨"""
        result = image_bytes

        for processor in self.processors:
            result = processor.process(result)

        return result


# ä½¿ç”¨ç¤ºä¾‹
# generator/image_generator.py
class ImageGenerator:
    def __init__(self, ..., postprocessors=None):
        self.postprocessors = postprocessors or []

    def generate_slides(self, plan, gen_input):
        # ç”ŸæˆåŸå§‹å›¾ç‰‡
        images = self._generate_all(plan, gen_input)

        # åº”ç”¨åå¤„ç†
        if self.postprocessors:
            pipeline = PostprocessorPipeline(self.postprocessors)
            images = [pipeline.process(img) for img in images]

        return images


# é…ç½®
postprocessors = [
    BorderPostprocessor(border_width=5, border_color=(220, 220, 220)),
    WatermarkPostprocessor(watermark_text="Â© 2023 My Lab"),
    CompressionPostprocessor(quality=90, max_size_mb=3)
]

generator = ImageGenerator(..., postprocessors=postprocessors)
```

---

## ğŸ”§ è°ƒè¯•å’Œæµ‹è¯•

### å•å…ƒæµ‹è¯•ç¤ºä¾‹

```python
# tests/test_content_planner.py
import pytest
from paper2slides.generator.content_planner import ContentPlanner
from paper2slides.summary.models import PaperContent, OriginalElements

@pytest.fixture
def sample_content():
    return PaperContent(
        paper_info="Title: Test Paper\nAuthors: John Doe",
        motivation="We address the problem of...",
        solution="We propose a novel method...",
        results="Experiments show 95% accuracy...",
        contributions="Main contributions: 1) ..."
    )

@pytest.fixture
def sample_origin():
    return OriginalElements(
        tables=[],
        figures=[],
        base_path="/tmp/test"
    )

def test_content_planner_short():
    """æµ‹è¯•çŸ­å¹»ç¯ç‰‡è§„åˆ’"""
    planner = ContentPlanner(mock_llm_client())

    plan = planner.plan(GenerationInput(
        content=sample_content(),
        origin=sample_origin(),
        output_type="slides",
        config={"slides_length": "short"}
    ))

    assert len(plan.sections) >= 5
    assert len(plan.sections) <= 8
    assert plan.sections[0].title  # æ ‡é¢˜é¡µ

def test_content_planner_with_figures():
    """æµ‹è¯•åŒ…å«å›¾ç‰‡çš„è§„åˆ’"""
    origin = OriginalElements(
        tables=[],
        figures=[
            FigureInfo("Figure 1", "Architecture", "/path/figure1.png")
        ],
        base_path="/tmp"
    )

    planner = ContentPlanner(mock_llm_client())
    plan = planner.plan(GenerationInput(..., origin=origin))

    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦è¢«åˆ†é…åˆ°æŸä¸€é¡µ
    has_figure = any(
        len(section.figures) > 0
        for section in plan.sections
    )
    assert has_figure
```

### é›†æˆæµ‹è¯•

```python
# tests/test_pipeline.py
import pytest
import asyncio
from paper2slides.core.pipeline import run_pipeline

@pytest.mark.asyncio
async def test_full_pipeline():
    """æµ‹è¯•å®Œæ•´æµæ°´çº¿"""
    config = {
        "input_path": "tests/fixtures/sample_paper.pdf",
        "content_type": "paper",
        "output_type": "slides",
        "style": "academic",
        "slides_length": "short",
        "fast_mode": True
    }

    base_dir = Path("tests/output/test_project/paper")
    config_dir = base_dir / "fast" / "slides_academic_short"

    # è¿è¡Œæµæ°´çº¿
    await run_pipeline(
        base_dir=base_dir,
        config_dir=config_dir,
        config=config,
        from_stage="rag"
    )

    # éªŒè¯è¾“å‡º
    assert (base_dir / "fast" / "checkpoint_rag.json").exists()
    assert (base_dir / "fast" / "checkpoint_summary.json").exists()
    assert (config_dir / "checkpoint_plan.json").exists()

    # æ£€æŸ¥ç”Ÿæˆçš„å›¾ç‰‡
    output_dir = list(config_dir.glob("*"))[0]
    slides = list(output_dir.glob("slide_*.png"))
    assert len(slides) >= 5


@pytest.mark.asyncio
async def test_resume_from_checkpoint():
    """æµ‹è¯•æ–­ç‚¹ç»­ä¼ """
    # ç¬¬ä¸€æ¬¡è¿è¡Œï¼ˆä¸­æ–­åœ¨ plan é˜¶æ®µï¼‰
    # ...

    # ç¬¬äºŒæ¬¡è¿è¡Œï¼ˆä» plan ç»§ç»­ï¼‰
    await run_pipeline(..., from_stage="plan")

    # éªŒè¯æ²¡æœ‰é‡å¤æ‰§è¡Œ RAG å’Œ Summary
    # ...
```

### æ€§èƒ½æµ‹è¯•

```python
# tests/test_performance.py
import time
import psutil

def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
    process = psutil.Process()

    initial_memory = process.memory_info().rss / (1024 * 1024)  # MB

    # è¿è¡Œæµæ°´çº¿
    run_pipeline(...)

    final_memory = process.memory_info().rss / (1024 * 1024)
    memory_increase = final_memory - initial_memory

    # ç¡®ä¿å†…å­˜å¢é•¿åœ¨åˆç†èŒƒå›´å†…ï¼ˆ< 2GBï¼‰
    assert memory_increase < 2000


def test_generation_speed():
    """æµ‹è¯•ç”Ÿæˆé€Ÿåº¦"""
    start_time = time.time()

    # ç”Ÿæˆ 10 é¡µå¹»ç¯ç‰‡
    generator.generate_slides(plan_with_10_pages, gen_input)

    elapsed = time.time() - start_time

    # ç¡®ä¿å¹³å‡æ¯é¡µ < 30 ç§’ï¼ˆä½¿ç”¨å¹¶è¡Œç”Ÿæˆï¼‰
    avg_per_slide = elapsed / 10
    assert avg_per_slide < 30
```

---

## ğŸ“¦ éƒ¨ç½²å»ºè®®

### Docker åŒ–

```dockerfile
# Dockerfile
FROM python:3.12-slim

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    git \
    poppler-utils \
    tesseract-ocr \
    && rm -rf /var/lib/apt/lists/*

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ä»£ç 
COPY . /app

# å®‰è£… Python ä¾èµ–
RUN pip install --no-cache-dir -e .

# æš´éœ²ç«¯å£
EXPOSE 8001

# å¯åŠ¨å‘½ä»¤
CMD ["python", "api/server.py", "8001"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  backend:
    build: .
    ports:
      - "8001:8001"
    volumes:
      - ./outputs:/app/outputs
      - ./sources:/app/sources
    environment:
      - RAG_LLM_API_KEY=${RAG_LLM_API_KEY}
      - IMAGE_GEN_PROVIDER=${IMAGE_GEN_PROVIDER:-openrouter}
      - IMAGE_GEN_API_KEY=${IMAGE_GEN_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
    restart: unless-stopped

  frontend:
    image: node:18-alpine
    working_dir: /app
    volumes:
      - ./frontend:/app
    ports:
      - "5173:5173"
    command: npm run dev
    depends_on:
      - backend
```

### ç”Ÿäº§ç¯å¢ƒé…ç½®

```python
# api/config.py
import os

class Config:
    """åŸºç¡€é…ç½®"""
    DEBUG = False
    TESTING = False

    # API å¯†é’¥
    RAG_LLM_API_KEY = os.getenv("RAG_LLM_API_KEY")
    IMAGE_GEN_API_KEY = os.getenv("IMAGE_GEN_API_KEY")

    # è·¯å¾„
    UPLOAD_DIR = "/data/uploads"
    OUTPUT_DIR = "/data/outputs"

    # é™åˆ¶
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
    MAX_UPLOAD_FILES = 10

    # å¹¶å‘
    MAX_CONCURRENT_TASKS = 3
    MAX_WORKERS_PER_TASK = 2


class DevelopmentConfig(Config):
    """å¼€å‘é…ç½®"""
    DEBUG = True
    UPLOAD_DIR = "sources/uploads"
    OUTPUT_DIR = "outputs"


class ProductionConfig(Config):
    """ç”Ÿäº§é…ç½®"""
    # ä½¿ç”¨ Redis å­˜å‚¨ä¼šè¯
    REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379")

    # ä½¿ç”¨ S3 å­˜å‚¨è¾“å‡º
    S3_BUCKET = os.getenv("S3_BUCKET")
    S3_ACCESS_KEY = os.getenv("S3_ACCESS_KEY")
    S3_SECRET_KEY = os.getenv("S3_SECRET_KEY")

    # æ—¥å¿—
    LOG_LEVEL = "INFO"
    LOG_FILE = "/var/log/paper2slides/app.log"


def get_config():
    env = os.getenv("FLASK_ENV", "development")

    if env == "production":
        return ProductionConfig()
    else:
        return DevelopmentConfig()
```

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. æç¤ºè¯å·¥ç¨‹

**åŸåˆ™**ï¼š
- è¯¦ç»†å…·ä½“ï¼šæ˜ç¡®æ¯ä¸ªè¦æ±‚
- ç»“æ„åŒ–è¾“å‡ºï¼šä½¿ç”¨ JSON æ¨¡å¼
- ç¤ºä¾‹é©±åŠ¨ï¼šæä¾›å°‘æ ·æœ¬ç¤ºä¾‹
- è¿­ä»£ä¼˜åŒ–ï¼šæ ¹æ®è¾“å‡ºè°ƒæ•´

**ç¤ºä¾‹**ï¼š
```python
# å·®çš„æç¤ºè¯
prompt = "æ€»ç»“è¿™ç¯‡è®ºæ–‡"

# å¥½çš„æç¤ºè¯
prompt = """
ä»ä»¥ä¸‹è®ºæ–‡å†…å®¹ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
{
  "title": "è®ºæ–‡å®Œæ•´æ ‡é¢˜",
  "authors": ["ä½œè€…1", "ä½œè€…2"],
  "institutions": ["æœºæ„1", "æœºæ„2"],
  "abstract": "æ‘˜è¦ï¼ˆæœ€å¤š200è¯ï¼‰",
  "key_contributions": ["è´¡çŒ®1", "è´¡çŒ®2", "è´¡çŒ®3"]
}

## è¦æ±‚
- ä¿ç•™åŸæ–‡çš„ä¸“ä¸šæœ¯è¯­
- æ•°å­—å’Œå•ä½ä¿æŒç²¾ç¡®
- å¦‚æœä¿¡æ¯ç¼ºå¤±ï¼Œä½¿ç”¨ null

## è®ºæ–‡å†…å®¹
{paper_text}

ç°åœ¨è¯·è¾“å‡º JSONï¼š
"""
```

### 2. é”™è¯¯å¤„ç†

```python
# å·®çš„é”™è¯¯å¤„ç†
def generate():
    result = api.call()
    return result


# å¥½çš„é”™è¯¯å¤„ç†
def generate(max_retries=3):
    for attempt in range(max_retries):
        try:
            result = api.call()
            return result

        except RateLimitError as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                logger.warning(f"Rate limited, waiting {wait_time}s...")
                time.sleep(wait_time)
            else:
                raise

        except APIError as e:
            logger.error(f"API error: {e}")
            raise

        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            raise


# æ›´å¥½ï¼šä½¿ç”¨è£…é¥°å™¨
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def generate():
    return api.call()
```

### 3. æ—¥å¿—è®°å½•

```python
# paper2slides/utils/logging.py
import logging
import sys

def setup_logger(name, level=logging.INFO):
    """é…ç½®æ—¥å¿—å™¨"""
    logger = logging.getLogger(name)
    logger.setLevel(level)

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)

    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler("paper2slides.log")
    file_handler.setLevel(logging.DEBUG)

    # æ ¼å¼åŒ–
    formatter = logging.Formatter(
        '[%(asctime)s] %(name)s - %(levelname)s - %(message)s'
    )
    console_handler.setFormatter(formatter)
    file_handler.setFormatter(formatter)

    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

    return logger


# ä½¿ç”¨
logger = setup_logger(__name__)

logger.info("Starting pipeline...")
logger.debug(f"Config: {config}")
logger.error(f"Failed to generate: {error}")
```

---

## ğŸš§ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1ï¼šç”Ÿæˆçš„å›¾ç‰‡æ–‡å­—æ¨¡ç³Š

**åŸå› **ï¼šé»˜è®¤åˆ†è¾¨ç‡ä¸å¤Ÿé«˜

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# åœ¨æç¤ºè¯ä¸­æ˜ç¡®æŒ‡å®šé«˜åˆ†è¾¨ç‡
prompt = """
åˆ›å»ºä¸€å¼ é«˜åˆ†è¾¨ç‡æ¼”ç¤ºå¹»ç¯ç‰‡ï¼ˆ3840x2160, 4Kè´¨é‡ï¼‰ã€‚

æ–‡å­—è¦æ±‚ï¼š
- æ‰€æœ‰æ–‡å­—æ¸…æ™°å¯è¯»
- æœ€å°å­—ä½“å¤§å°ï¼š24pt
- ä½¿ç”¨æŠ—é”¯é½¿æ¸²æŸ“
...
"""

# æˆ–åå¤„ç†æå‡åˆ†è¾¨ç‡
images = [upscale_image(img, target_width=3840) for img in images]
```

### é—®é¢˜ 2ï¼šRAG æŸ¥è¯¢è¿”å›ä¸ç›¸å…³å†…å®¹

**åŸå› **ï¼šæŸ¥è¯¢é—®é¢˜è¿‡äºå®½æ³›æˆ–æ¨¡ç³Š

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å·®çš„æŸ¥è¯¢
"è®ºæ–‡çš„æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ"

# å¥½çš„æŸ¥è¯¢
"è®ºæ–‡æå‡ºäº†ä»€ä¹ˆå…·ä½“çš„ç®—æ³•æˆ–æ¨¡å‹æ¶æ„ï¼Ÿè¯·è¯¦ç»†æè¿°ä¸»è¦ç»„ä»¶ã€è¾“å…¥è¾“å‡ºã€ä»¥åŠä¸ç°æœ‰æ–¹æ³•çš„åŒºåˆ«ã€‚"

# æˆ–ä½¿ç”¨å¤šä¸ªå…·ä½“æŸ¥è¯¢
queries = [
    "è®ºæ–‡æå‡ºçš„æ¨¡å‹æ¶æ„åç§°æ˜¯ä»€ä¹ˆï¼Ÿ",
    "æ¨¡å‹åŒ…å«å“ªäº›ä¸»è¦æ¨¡å—æˆ–ç»„ä»¶ï¼Ÿæ¯ä¸ªç»„ä»¶çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ",
    "æ¨¡å‹çš„è¾“å…¥æ˜¯ä»€ä¹ˆï¼Ÿè¾“å‡ºæ˜¯ä»€ä¹ˆï¼Ÿ",
    "ä¸ baseline æ–¹æ³•ç›¸æ¯”ï¼Œæ–°æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨å“ªé‡Œï¼Ÿ"
]
```

### é—®é¢˜ 3ï¼šç”Ÿæˆé€Ÿåº¦æ…¢

**åŸå› **ï¼šé¡ºåºç”Ÿæˆæ‰€æœ‰é¡µé¢

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ä½¿ç”¨å¹¶è¡Œç”Ÿæˆ
python -m paper2slides --input paper.pdf --parallel 4

# æˆ–ä½¿ç”¨ fast æ¨¡å¼ï¼ˆè·³è¿‡ RAG ç´¢å¼•ï¼‰
python -m paper2slides --input paper.pdf --fast
```

### é—®é¢˜ 4ï¼šé£æ ¼ä¸ä¸€è‡´

**åŸå› **ï¼šæ¯é¡µç‹¬ç«‹ç”Ÿæˆï¼Œæ²¡æœ‰å‚è€ƒ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å½“å‰å·²å®ç°ï¼šä½¿ç”¨ç¬¬ 2 é¡µä½œä¸ºé£æ ¼å‚è€ƒ

# è¿›ä¸€æ­¥æ”¹è¿›ï¼šä½¿ç”¨æ›´å¼ºçš„é£æ ¼çº¦æŸ
style_reference = {
    "figure_id": "Style Reference",
    "caption": """
        CRITICAL: Maintain EXACT style consistency:
        - Background color: #FFFFFF (no variations)
        - Primary accent: #1e3a8a
        - Font: Roboto, 48pt for headers, 32pt for body
        - Layout: 80px margins, centered alignment
        - NO decorative elements beyond simple lines
    """,
    "base64": reference_image_base64
}
```

---

## ğŸ“š æ¨èå­¦ä¹ èµ„æº

### æŠ€æœ¯æ ˆç›¸å…³
1. **FastAPI**: https://fastapi.tiangolo.com/
2. **LightRAG**: https://github.com/HKUDS/LightRAG
3. **OpenAI API**: https://platform.openai.com/docs/
4. **React**: https://react.dev/

### RAG å’Œæç¤ºè¯å·¥ç¨‹
1. **Prompt Engineering Guide**: https://www.promptingguide.ai/
2. **RAG æœ€ä½³å®è·µ**: https://arxiv.org/abs/2312.10997
3. **å¤šæ¨¡æ€ LLM**: https://arxiv.org/abs/2306.13549

### ä»£ç ç¤ºä¾‹
- æœ¬é¡¹ç›® GitHub: (é¡¹ç›®ä»“åº“åœ°å€)
- ç¤ºä¾‹è®ºæ–‡å’Œè¾“å‡º: `examples/` ç›®å½•

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

å¦‚æœä½ æƒ³ä¸º Paper2Slides è´¡çŒ®ä»£ç ï¼š

1. **Fork é¡¹ç›®**
2. **åˆ›å»ºç‰¹æ€§åˆ†æ”¯**: `git checkout -b feature/amazing-feature`
3. **ç¼–å†™ä»£ç å’Œæµ‹è¯•**
4. **æäº¤**: `git commit -m 'Add amazing feature'`
5. **æ¨é€**: `git push origin feature/amazing-feature`
6. **åˆ›å»º Pull Request**

### ä»£ç é£æ ¼
- éµå¾ª PEP 8
- ä½¿ç”¨ç±»å‹æç¤º
- ç¼–å†™æ–‡æ¡£å­—ç¬¦ä¸²
- æ·»åŠ å•å…ƒæµ‹è¯•

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ `LICENSE` æ–‡ä»¶ã€‚

---

**ç”Ÿæˆæ—¥æœŸ**: 2025-12-10
**æ–‡æ¡£ç‰ˆæœ¬**: 1.1
**æœ€åæ›´æ–°**: æ·»åŠ å›¾åƒç”Ÿæˆæä¾›å•†ç³»ç»Ÿï¼ˆOpenRouter/Google GenAIï¼‰
**ä½œè€…**: Paper2Slides Team

---

*å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ Issue æˆ–è”ç³»ç»´æŠ¤è€…ã€‚*
